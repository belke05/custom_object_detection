{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_object_detector.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw59JoZ4-_3X",
        "colab_type": "text"
      },
      "source": [
        "# Creating my custom object detector\n",
        "\n",
        "why object detection:\n",
        "\n",
        "*  want to detect multiple objects \n",
        "*  want to detect different object \n",
        "*  want to count objects\n",
        "\n",
        "\n",
        "difference with classification:\n",
        "\n",
        "*  extract features from labeled parts of images instead of whole image\n",
        "*  get pictures represntative for test case\n",
        "\n",
        "<h1>concept refresh</h1>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "-  <h4><a href=\"https://colab.research.google.com/drive/1rbYvb6vDelDkz13UJoFF38WvBjpIxBWt\">CONVOLUTIONAL LAYER</a></h4>\n",
        "-  <h4><a href=\"https://colab.research.google.com/drive/1rbYvb6vDelDkz13UJoFF38WvBjpIxBWt\">EVALUATION METRICS</a></h4>\n",
        "- <h4><a href=\"https://colab.research.google.com/drive/1rbYvb6vDelDkz13UJoFF38WvBjpIxBWt\">IMAGE GRADIENT VECTOR</a></h4>\n",
        "\n",
        "<h1>which model to use?</h1>\n",
        "\n",
        "---\n",
        "\n",
        "<table style=\"width:100%\">\n",
        "  <tr>\n",
        "    <th>name</th>\n",
        "    <th>type</th>\n",
        "    <th>pros</th>\n",
        "    <th>cons</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>faster cnn</td>\n",
        "    <td>faster training  / more accurate</td>\n",
        "    <td>slower detection / requires stronger device</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>mobile net</td>\n",
        "    <td>Single Shot Detector</td>\n",
        "    <td>faster detection / works better with video</td>\n",
        "    <td>slower training / less accurate</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "---\n",
        "\n",
        "<h1>file structure</h1>\n",
        "<span id=\"e0f3\" class=\"ki kj fa ar lx b bj ml mm r mn\" data-selectable-paragraph=\"\">\n",
        "object_detection/<br>├── data/<br>           │    ├── images/<br>           │    │      └── ...<br>           │    ├── <!-- -->annotations/<br>           │    │      └── ...<br>           │    ├── train_labels/<br>           │    │      └── ...<br>           │    ├── <!-- -->test_labels/<br>           │    │      └── ...<br>           │    ├── label_map.pbtxt<br>           │    ├── test_labels.csv<br>           │    ├── train_labels.csv<br>           │    ├── test_labels.records<br>           │    └── train_labels.records<br>           │<br>           └── models/           <br>                ├── research/<br>                │      ├── training/<br>                │      │      <!-- -->└── ...<br>                │      <!-- -->├── pretrained_model/<br>                <br>                │      ├── frozen_inference_graph.pb<br>                │      └── ...<br>                └── ...</span>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l0tQyF4_IBm",
        "colab_type": "text"
      },
      "source": [
        "#get needed packages / libraries \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riO8EBnLiqwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b899d35e-a318-41a4-bccd-82367ddf2001"
      },
      "source": [
        "maindirectory = input('insert the name you want to give main directory \\n')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "insert the name you want to give main directory \n",
            "my_detector2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1dMXykpuIOg",
        "colab_type": "code",
        "outputId": "d199d4a3-6ddb-49d5-e66b-0c366cf1cdb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# installing some utilities \n",
        "!pip install simple_chalk\n",
        "!pip install pprint\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -qq pycocotools\n",
        "\n",
        "\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, tensorflow.compat.v1 as tf\n",
        "import csv, re, os, io, glob, shutil, urllib.request, pathlib\n",
        "import tarfile, xml.etree.ElementTree as ET, cv2\n",
        "from PIL import Image\n",
        "from collections import namedtuple, OrderedDict\n",
        "from google.colab import files\n",
        "import matplotlib.image as mpimg\n",
        "from google.colab.patches import cv2_imshow\n",
        "from pprint import pprint\n",
        "from simple_chalk import chalk, green, red, blue, yellow\n",
        "\n",
        "# make sure we train on a GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# we need tenorflow v 1.15.0, object detection API is removed from tf v 2.0+\n",
        "\n",
        "print(red(tf.__version__))\n",
        "print(blue(pathlib.Path.cwd()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simple_chalk\n",
            "  Downloading https://files.pythonhosted.org/packages/31/97/b8114a347aee340570eb92b1a1fe512a038766903af7aa4e28447dc25c80/simple_chalk-0.1.0.tar.gz\n",
            "Building wheels for collected packages: simple-chalk\n",
            "  Building wheel for simple-chalk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simple-chalk: filename=simple_chalk-0.1.0-cp36-none-any.whl size=22161 sha256=7399e3ca08efff2bfc153b9a7209d3b76a1a5f973c52ff41e2cafb2dc236aebf\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/81/ae/ad4681309e28c08419ba5c41d60ccddfc050a6d6a089f79a89\n",
            "Successfully built simple-chalk\n",
            "Installing collected packages: simple-chalk\n",
            "Successfully installed simple-chalk-0.1.0\n",
            "Collecting pprint\n",
            "  Downloading https://files.pythonhosted.org/packages/99/12/b6383259ef85c2b942ab9135f322c0dce83fdca8600d87122d2b0181451f/pprint-0.1.tar.gz\n",
            "Building wheels for collected packages: pprint\n",
            "  Building wheel for pprint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pprint: filename=pprint-0.1-cp36-none-any.whl size=1250 sha256=0b590f691af1850291b403ccda81ea94ba32543b5126540e15dcc794c7f15ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/d4/c6/16a6495aecc1bda5d5857bd036efd50617789ba9bea4a05124\n",
            "Successfully built pprint\n",
            "Installing collected packages: pprint\n",
            "Successfully installed pprint-0.1\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 145674 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "\u001b[31m1.15.0\u001b[0m\n",
            "\u001b[34m/content\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c1BwgW-_NNU",
        "colab_type": "text"
      },
      "source": [
        "# create drive directory to work with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTiW8fFfWq0b",
        "colab_type": "code",
        "outputId": "cec6de83-a2e1-4e06-d136-2732a58a56fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# %cd /content/drive/'My Drive'/\n",
        "# %mkdir $maindirectory\n",
        "%cd /content/drive/'My Drive'/$maindirectory\n",
        "\n",
        "# if no data directory present yet \n",
        "# %mkdir data\n",
        "# %cd /content/drive/'My Drive'/my_detector2/data\n",
        "# %mkdir images"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJzt5_ySXHqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/'My Drive'/$maindirectory\n",
        "\n",
        "# downloads the models\n",
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzfUKWyQsxMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be6bd742-a05f-4c3c-8124-a6b1dc873986"
      },
      "source": [
        "# compile into python files\n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# set env variables  \n",
        "# change directory name\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/My Drive/my_detector/models/research/:/content/drive/My Drive/my_detector2/models/research/slim'\n",
        "os.environ['PYTHONPATH'] += ':./:./slim/'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP5UWpCx_YnV",
        "colab_type": "text"
      },
      "source": [
        "# generate tf.record files based upon train_labels csv and image specified \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykLfpKT4n-G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO-DO replace this with label map -- in the genrate_tfrecord.py file\n",
        "\n",
        "# def class_text_to_int(row_label):\n",
        "#   if row_label == 'banana':\n",
        "#     return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg3K0w4Ow5tX",
        "colab_type": "code",
        "outputId": "0d10d879-ddb2-4e4a-cf66-644e2b8b0d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "source": [
        "# something wrong here / change the maindirectory name \n",
        "\n",
        "%cd /content/drive/'My Drive'/my_detector2\n",
        "\n",
        "!python3 generate_tfrecord.py \\\n",
        " --csv_input=./data/train_labels.csv \\\n",
        " --output_path=./data/train.record \\\n",
        " --image_dir=./data/images\n",
        "\n",
        "!python3 generate_tfrecord.py \\\n",
        "--csv_input=./data/test_labels.csv \\\n",
        "--output_path=./data/test.record \\\n",
        "--image_dir=./data/images\n",
        "\n",
        "# will generate a test.record and train.record in the data directory"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2\n",
            "WARNING:tensorflow:From generate_tfrecord.py:117: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "read split\n",
            "WARNING:tensorflow:From generate_tfrecord.py:99: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0123 15:28:22.709259 139734537508736 module_wrapper.py:139] From generate_tfrecord.py:99: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "read split\n",
            "grouped split\n",
            "WARNING:tensorflow:From generate_tfrecord.py:56: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0123 15:28:22.810578 139734537508736 module_wrapper.py:139] From generate_tfrecord.py:56: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "writer closed\n",
            "Successfully created the TFRecords: /content/drive/My Drive/my_detector2/./data/train.record\n",
            "WARNING:tensorflow:From generate_tfrecord.py:117: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "read split\n",
            "WARNING:tensorflow:From generate_tfrecord.py:99: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0123 15:29:40.808195 140513495152512 module_wrapper.py:139] From generate_tfrecord.py:99: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "read split\n",
            "grouped split\n",
            "WARNING:tensorflow:From generate_tfrecord.py:56: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0123 15:29:40.839957 140513495152512 module_wrapper.py:139] From generate_tfrecord.py:56: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "writer closed\n",
            "Successfully created the TFRecords: /content/drive/My Drive/my_detector2/./data/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqpbuPcQm0hQ",
        "colab_type": "text"
      },
      "source": [
        "# get the model to use / configure pipeling \n",
        "\n",
        "[model options](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uta2J4PyxIUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some models to train on\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# Select a model from `MODELS_CONFIG`.\n",
        "selected_model = 'faster_rcnn_inception_v2'\n",
        "configfilename = 'faster_rcnn_inception_v2_pets.config'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJkpx_cLzZX6",
        "colab_type": "code",
        "outputId": "e0e07cc5-8178-4a1d-9707-c8e1bf0bb547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# the distination folder where the model will be saved\n",
        "# change this if you have a different working dir\n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research\n",
        "\n",
        "# folder in which there is already a model.ckpt / frozen inference graph \n",
        "# and a pipeling.config\n",
        "DEST_DIR = '/content/drive/My Drive/{0}/models/research/pretrained_model'.format(maindirectory)\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "#selecting the model\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "\n",
        "#creating the download link for the model selected\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# if model not downloaded download now \n",
        "!pwd\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    print('here')\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "#unzipping the model and extracting its content\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# creating an output file to save the model while training\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n",
            "/content/drive/My Drive/my_detector2/models/research\n",
            "here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiaoVlZQPuaU",
        "colab_type": "code",
        "outputId": "403fa409-e4ac-4fff-92d5-d9f7620974b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Create a folder called training inside object_detection/model/research/\n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research\n",
        "%mkdir training\n",
        "# this directory will hold the model.ckpts of our training \n",
        "# of which we can generate a frozen inference graph later"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n",
            "mkdir: cannot create directory ‘training’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-6R2LzLvCi9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aea205bc-1871-4447-f970-f44faf236d82"
      },
      "source": [
        "# optional listing of all existing configs \n",
        "!ls /content/drive/'My Drive'/$maindirectory/models/research/object_detection/samples/configs\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedded_ssd_mobilenet_v1_coco.config\n",
            "facessd_mobilenet_v2_quantized_320x320_open_image_v4.config\n",
            "faster_rcnn_inception_resnet_v2_atrous_coco.config\n",
            "faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config\n",
            "faster_rcnn_inception_resnet_v2_atrous_oid.config\n",
            "faster_rcnn_inception_resnet_v2_atrous_oid_v4.config\n",
            "faster_rcnn_inception_resnet_v2_atrous_pets.config\n",
            "faster_rcnn_inception_v2_coco.config\n",
            "faster_rcnn_inception_v2_pets.config\n",
            "faster_rcnn_nas_coco.config\n",
            "faster_rcnn_resnet101_atrous_coco.config\n",
            "faster_rcnn_resnet101_ava_v2.1.config\n",
            "faster_rcnn_resnet101_coco.config\n",
            "faster_rcnn_resnet101_fgvc.config\n",
            "faster_rcnn_resnet101_kitti.config\n",
            "faster_rcnn_resnet101_pets.config\n",
            "faster_rcnn_resnet101_voc07.config\n",
            "faster_rcnn_resnet152_coco.config\n",
            "faster_rcnn_resnet152_pets.config\n",
            "faster_rcnn_resnet50_coco.config\n",
            "faster_rcnn_resnet50_fgvc.config\n",
            "faster_rcnn_resnet50_pets.config\n",
            "mask_rcnn_inception_resnet_v2_atrous_coco.config\n",
            "mask_rcnn_inception_v2_coco.config\n",
            "mask_rcnn_resnet101_atrous_coco.config\n",
            "mask_rcnn_resnet101_pets.config\n",
            "mask_rcnn_resnet50_atrous_coco.config\n",
            "rfcn_resnet101_coco.config\n",
            "rfcn_resnet101_pets.config\n",
            "ssd_inception_v2_coco.config\n",
            "ssd_inception_v2_pets.config\n",
            "ssd_inception_v3_pets.config\n",
            "ssdlite_mobilenet_edgetpu_320x320_coco.config\n",
            "ssdlite_mobilenet_edgetpu_320x320_coco_quant.config\n",
            "ssdlite_mobilenet_v1_coco.config\n",
            "ssdlite_mobilenet_v2_coco.config\n",
            "ssdlite_mobilenet_v3_large_320x320_coco.config\n",
            "ssdlite_mobilenet_v3_small_320x320_coco.config\n",
            "ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config\n",
            "ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config\n",
            "ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config\n",
            "ssd_mobilenet_v1_300x300_coco14_sync.config\n",
            "ssd_mobilenet_v1_coco.config\n",
            "ssd_mobilenet_v1_focal_loss_pets.config\n",
            "ssd_mobilenet_v1_focal_loss_pets_inference.config\n",
            "ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\n",
            "ssd_mobilenet_v1_pets.config\n",
            "ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config\n",
            "ssd_mobilenet_v1_quantized_300x300_coco14_sync.config\n",
            "ssd_mobilenet_v2_coco.config\n",
            "ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config\n",
            "ssd_mobilenet_v2_fullyconv_coco.config\n",
            "ssd_mobilenet_v2_oid_v4.config\n",
            "ssd_mobilenet_v2_pets_keras.config\n",
            "ssd_mobilenet_v2_quantized_300x300_coco.config\n",
            "ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yfvoeU1zutL",
        "colab_type": "code",
        "outputId": "baf55fa4-a7a5-47bb-e00b-7d8d2896f101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# change the type of preconfig you want to use here \n",
        "\n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research\n",
        "!cat object_detection/samples/configs/$configfilename"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n",
            "\n",
            "\n",
            "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 6\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'faster_rcnn_inception_v2'\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        scales: [0.25, 0.5, 1.0, 2.0]\n",
            "        aspect_ratios: [0.5, 1.0, 2.0]\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 1\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.0002\n",
            "          schedule {\n",
            "            step: 900000\n",
            "            learning_rate: .00002\n",
            "          }\n",
            "          schedule {\n",
            "            step: 1200000\n",
            "            learning_rate: .000002\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/drive/My Drive/my_detector2/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 200000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/drive/My Drive/my_detector2/data/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/drive/My Drive/my_detector2/data/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  num_examples: 72\n",
            "  max_evals: 10 \n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/drive/My Drive/my_detector2/data/test.record\"\n",
            "  }\n",
            "  label_map_path:  \"/content/drive/My Drive/my_detector2/data/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIAnj1DswCbb",
        "colab_type": "text"
      },
      "source": [
        "things to change:\n",
        "\n",
        "*  number of classes possible to detect\n",
        "*  fine tune checkpoint from which to we will start which we downloaded earlier and put in the pretrained_model folder \n",
        "*  input (tf record input made earlier) and label map path \n",
        "*  num examples for eval config = #images in test directory \n",
        "*  evaluation input reader and label map (which is same as for test)\n",
        "*  max evals in the evaluation\n",
        "*  change writefile to configfilename "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yc9LDg5zhpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9dda7383-b27b-4da1-b09f-6a16d78c5a5e"
      },
      "source": [
        "# don't forget to change the directory in the paths you configure\n",
        "print(red(maindirectory))\n",
        "print(green(configfilename))\n",
        "# path joining version for other paths\n",
        "DIR = '/content/drive/My Drive/{0}/data/test'.format(maindirectory)\n",
        "print(blue('# images to test on:'))\n",
        "print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mmy_detector2\u001b[0m\n",
            "\u001b[32mfaster_rcnn_inception_v2_pets.config\u001b[0m\n",
            "\u001b[34m# images to test on:\u001b[0m\n",
            "72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adjWIE6392UF",
        "colab_type": "code",
        "outputId": "a698adb5-60a9-4e5d-893a-0880694b6a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#path to the config file\n",
        "\n",
        "%%writefile object_detection/samples/configs/faster_rcnn_inception_v2_pets.config\n",
        "\n",
        "\n",
        "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  faster_rcnn {\n",
        "    num_classes: 6\n",
        "    image_resizer {\n",
        "      keep_aspect_ratio_resizer {\n",
        "        min_dimension: 600\n",
        "        max_dimension: 1024\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'faster_rcnn_inception_v2'\n",
        "      first_stage_features_stride: 16\n",
        "    }\n",
        "    first_stage_anchor_generator {\n",
        "      grid_anchor_generator {\n",
        "        scales: [0.25, 0.5, 1.0, 2.0]\n",
        "        aspect_ratios: [0.5, 1.0, 2.0]\n",
        "        height_stride: 16\n",
        "        width_stride: 16\n",
        "      }\n",
        "    }\n",
        "    first_stage_box_predictor_conv_hyperparams {\n",
        "      op: CONV\n",
        "      regularizer {\n",
        "        l2_regularizer {\n",
        "          weight: 0.0\n",
        "        }\n",
        "      }\n",
        "      initializer {\n",
        "        truncated_normal_initializer {\n",
        "          stddev: 0.01\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    first_stage_nms_score_threshold: 0.0\n",
        "    first_stage_nms_iou_threshold: 0.7\n",
        "    first_stage_max_proposals: 300\n",
        "    first_stage_localization_loss_weight: 2.0\n",
        "    first_stage_objectness_loss_weight: 1.0\n",
        "    initial_crop_size: 14\n",
        "    maxpool_kernel_size: 2\n",
        "    maxpool_stride: 2\n",
        "    second_stage_box_predictor {\n",
        "      mask_rcnn_box_predictor {\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 1.0\n",
        "        fc_hyperparams {\n",
        "          op: FC\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.0\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            variance_scaling_initializer {\n",
        "              factor: 1.0\n",
        "              uniform: true\n",
        "              mode: FAN_AVG\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    second_stage_post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 0.0\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 300\n",
        "      }\n",
        "      score_converter: SOFTMAX\n",
        "    }\n",
        "    second_stage_localization_loss_weight: 2.0\n",
        "    second_stage_classification_loss_weight: 1.0\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 1\n",
        "  optimizer {\n",
        "    momentum_optimizer: {\n",
        "      learning_rate: {\n",
        "        manual_step_learning_rate {\n",
        "          initial_learning_rate: 0.0002\n",
        "          schedule {\n",
        "            step: 900000\n",
        "            learning_rate: .00002\n",
        "          }\n",
        "          schedule {\n",
        "            step: 1200000\n",
        "            learning_rate: .000002\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  gradient_clipping_by_norm: 10.0\n",
        "  fine_tune_checkpoint: \"/content/drive/My Drive/my_detector2/models/research/pretrained_model/model.ckpt\"\n",
        "  from_detection_checkpoint: true\n",
        "  load_all_detection_checkpoint_vars: true\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 200000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/drive/My Drive/my_detector2/data/train.record\"\n",
        "  }\n",
        "  label_map_path: \"/content/drive/My Drive/my_detector2/data/label_map.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  num_examples: 72\n",
        "  max_evals: 10 \n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/drive/My Drive/my_detector2/data/test.record\"\n",
        "  }\n",
        "  label_map_path:  \"/content/drive/My Drive/my_detector2/data/label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting object_detection/samples/configs/faster_rcnn_inception_v2_pets.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mixr8VxO975g",
        "colab_type": "code",
        "outputId": "93e82205-e435-458d-99da-3cf97f4f0987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat object_detection/samples/configs/$configfilename"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 6\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'faster_rcnn_inception_v2'\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        scales: [0.25, 0.5, 1.0, 2.0]\n",
            "        aspect_ratios: [0.5, 1.0, 2.0]\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 1\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.0002\n",
            "          schedule {\n",
            "            step: 900000\n",
            "            learning_rate: .00002\n",
            "          }\n",
            "          schedule {\n",
            "            step: 1200000\n",
            "            learning_rate: .000002\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/drive/My Drive/my_detector2/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 200000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/drive/My Drive/my_detector2/data/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/drive/My Drive/my_detector2/data/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 72\n",
            "  max_evals: 10 \n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/drive/My Drive/my_detector2/data/test.record\"\n",
            "  }\n",
            "  label_map_path:  \"/content/drive/My Drive/my_detector2/data/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9RM4SFY4pZU",
        "colab_type": "text"
      },
      "source": [
        "# getting it integrated with tensorboard\n",
        "\n",
        "*  make sure you have drive synced on your pc for this \n",
        "*  in command line you can start up tensorboard and point to folder in which train / eval information is saved "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-OleC9m-FYS",
        "colab_type": "code",
        "outputId": "2508da55-6e25-49d0-b566-022354dff7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "%cd /content/drive/'My Drive'/$maindirectory/models/research\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n",
            "--2020-01-24 08:44:37--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.196.154.11, 52.54.249.116, 34.204.59.252, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.196.154.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  13.0MB/s    in 1.0s    \n",
            "\n",
            "2020-01-24 08:44:39 (13.0 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798N5RntCTzS",
        "colab_type": "code",
        "outputId": "2610eb36-f128-4ee0-e0b5-a823187662b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#the logs that are created while training \n",
        "# in the training folder we made earlier\n",
        "# this is where we will save checkpoints and inference graph  \n",
        "LOG_DIR = \"training/\"\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "#The link to tensorboard.\n",
        "#works after the training starts.\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://0e14c415.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNIVuEpwxu42",
        "colab_type": "text"
      },
      "source": [
        "`$ pip install tensorflow==1.15.0`\n",
        "\n",
        "`$ tensorboard --logdir=D:\\drive_files/my_detector/models/research/training`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_BEwA_FC5rL",
        "colab_type": "text"
      },
      "source": [
        "# training \n",
        "\n",
        "*  every few minutes a checkpoint is saved "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAy-vxDeCYGl",
        "colab_type": "code",
        "outputId": "6807abc1-8980-441c-97c2-0691bbd1519b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# pipeline was configured up we are pointing to the file location now \n",
        "\n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research/\n",
        "!python3 object_detection/model_main.py \\\n",
        "    --pipeline_config_path=/content/drive/My\\ Drive/$maindirectory/models/research/object_detection/samples/configs/$configfilename \\\n",
        "    --model_dir=training/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0124 08:46:48.490504 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0124 08:46:48.496879 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0124 08:46:48.497099 139920538380160 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0124 08:46:48.497291 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0124 08:46:48.497423 139920538380160 config_util.py:488] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0124 08:46:48.497552 139920538380160 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0124 08:46:48.497687 139920538380160 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0124 08:46:48.497899 139920538380160 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0124 08:46:48.498085 139920538380160 config_util.py:488] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0124 08:46:48.498232 139920538380160 config_util.py:498] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0124 08:46:48.498809 139920538380160 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0124 08:46:48.499155 139920538380160 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4161f779b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0124 08:46:48.499776 139920538380160 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4161f779b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f4161f7b730>) includes params argument, but params are not passed to Estimator.\n",
            "W0124 08:46:48.500088 139920538380160 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f4161f7b730>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0124 08:46:48.500703 139920538380160 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0124 08:46:48.500926 139920538380160 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0124 08:46:48.501269 139920538380160 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0124 08:46:49.958514 139920538380160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0124 08:46:49.974392 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0124 08:46:49.974724 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0124 08:46:50.203136 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0124 08:46:50.206333 139920538380160 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0124 08:46:50.212731 139920538380160 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0124 08:46:50.212912 139920538380160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0124 08:46:50.235757 139920538380160 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
            "\n",
            "W0124 08:46:53.013660 139920538380160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W0124 08:47:01.444380 139920538380160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0124 08:47:01.528883 139920538380160 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0124 08:47:04.135563 139920538380160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0124 08:47:06.703411 139920538380160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0124 08:47:07.750230 139920538380160 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "W0124 08:47:10.884561 139920538380160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0124 08:47:11.410506 139920538380160 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0124 08:47:11.425055 139920538380160 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0124 08:47:11.446749 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0124 08:47:11.458767 139920538380160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0124 08:47:13.204379 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 08:47:13.212624 139920538380160 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0124 08:47:13.212948 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 08:47:13.228975 139920538380160 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0124 08:47:13.229322 139920538380160 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0124 08:47:13.969706 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "W0124 08:47:14.019509 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0124 08:47:14.275751 139920538380160 deprecation.py:506] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0124 08:47:14.291009 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0124 08:47:15.021246 139920538380160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 08:47:15.023825 139920538380160 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 08:47:15.045882 139920538380160 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W0124 08:47:15.077589 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0124 08:47:15.077801 139920538380160 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0124 08:47:15.078690 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/variables_helper.py:142: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0124 08:47:15.083444 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/variables_helper.py:142: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0124 08:47:15.085498 139920538380160 variables_helper.py:154] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[360]], model variable shape: [[24]]. This variable will not be initialized from the checkpoint.\n",
            "W0124 08:47:15.085633 139920538380160 variables_helper.py:154] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1024, 360]], model variable shape: [[1024, 24]]. This variable will not be initialized from the checkpoint.\n",
            "W0124 08:47:15.085793 139920538380160 variables_helper.py:154] Variable [SecondStageBoxPredictor/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[91]], model variable shape: [[7]]. This variable will not be initialized from the checkpoint.\n",
            "W0124 08:47:15.085980 139920538380160 variables_helper.py:154] Variable [SecondStageBoxPredictor/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1024, 91]], model variable shape: [[1024, 7]]. This variable will not be initialized from the checkpoint.\n",
            "W0124 08:47:15.086871 139920538380160 variables_helper.py:157] Variable [global_step] is not available in checkpoint\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0124 08:47:15.087184 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0124 08:47:16.471389 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0124 08:47:16.472955 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0124 08:47:16.533172 139920538380160 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2710: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0124 08:47:16.813279 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2710: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0124 08:47:16.814218 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "W0124 08:47:16.824027 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0124 08:47:16.824332 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:408: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0124 08:47:16.824589 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:408: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0124 08:47:20.876647 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0124 08:47:21.393238 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W0124 08:47:21.393546 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0124 08:47:21.393904 139920538380160 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0124 08:47:21.395411 139920538380160 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0124 08:47:23.690704 139920538380160 monitored_session.py:240] Graph was finalized.\n",
            "2020-01-24 08:47:23.696584: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-01-24 08:47:23.696804: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1076d480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-24 08:47:23.696834: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-01-24 08:47:23.698708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-01-24 08:47:23.794388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:47:23.795322: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1076d2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-24 08:47:23.795380: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-01-24 08:47:23.795616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:47:23.796470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-24 08:47:23.796820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-24 08:47:23.798424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-24 08:47:23.800263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-24 08:47:23.800667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-24 08:47:23.802586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-24 08:47:23.803445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-24 08:47:23.807153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-24 08:47:23.807278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:47:23.808127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:47:23.808860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-24 08:47:23.808920: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-24 08:47:23.810310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-01-24 08:47:23.810338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-01-24 08:47:23.810366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-01-24 08:47:23.810536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:47:23.811601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:47:23.812574: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-01-24 08:47:23.812646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-0\n",
            "I0124 08:47:23.817326 139920538380160 saver.py:1284] Restoring parameters from training/model.ckpt-0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0124 08:47:34.587782 139920538380160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0124 08:47:35.223107 139920538380160 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0124 08:47:35.400469 139920538380160 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0124 08:47:41.532327 139920538380160 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-01-24 08:47:46.377762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-24 08:47:49.092062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 3.1713617, step = 0\n",
            "I0124 08:47:54.921407 139920538380160 basic_session_run_hooks.py:262] loss = 3.1713617, step = 0\n",
            "INFO:tensorflow:global_step/sec: 6.64014\n",
            "I0124 08:48:09.980409 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 6.64014\n",
            "INFO:tensorflow:loss = 2.4906063, step = 100 (15.061 sec)\n",
            "I0124 08:48:09.981863 139920538380160 basic_session_run_hooks.py:260] loss = 2.4906063, step = 100 (15.061 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.19792\n",
            "I0124 08:48:20.852375 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.19792\n",
            "INFO:tensorflow:loss = 1.0200502, step = 200 (10.871 sec)\n",
            "I0124 08:48:20.853364 139920538380160 basic_session_run_hooks.py:260] loss = 1.0200502, step = 200 (10.871 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.26029\n",
            "I0124 08:48:31.651201 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.26029\n",
            "INFO:tensorflow:loss = 0.48185188, step = 300 (10.799 sec)\n",
            "I0124 08:48:31.652182 139920538380160 basic_session_run_hooks.py:260] loss = 0.48185188, step = 300 (10.799 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.24959\n",
            "I0124 08:48:42.462466 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.24959\n",
            "INFO:tensorflow:loss = 0.49987683, step = 400 (10.811 sec)\n",
            "I0124 08:48:42.463504 139920538380160 basic_session_run_hooks.py:260] loss = 0.49987683, step = 400 (10.811 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.25326\n",
            "I0124 08:48:53.269491 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.25326\n",
            "INFO:tensorflow:loss = 0.9606993, step = 500 (10.807 sec)\n",
            "I0124 08:48:53.270540 139920538380160 basic_session_run_hooks.py:260] loss = 0.9606993, step = 500 (10.807 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.27728\n",
            "I0124 08:49:04.048511 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.27728\n",
            "INFO:tensorflow:loss = 0.41285926, step = 600 (10.779 sec)\n",
            "I0124 08:49:04.049459 139920538380160 basic_session_run_hooks.py:260] loss = 0.41285926, step = 600 (10.779 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.21852\n",
            "I0124 08:49:14.896239 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.21852\n",
            "INFO:tensorflow:loss = 0.4501057, step = 700 (10.848 sec)\n",
            "I0124 08:49:14.897294 139920538380160 basic_session_run_hooks.py:260] loss = 0.4501057, step = 700 (10.848 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.27446\n",
            "I0124 08:49:25.678632 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.27446\n",
            "INFO:tensorflow:loss = 0.5074905, step = 800 (10.783 sec)\n",
            "I0124 08:49:25.679993 139920538380160 basic_session_run_hooks.py:260] loss = 0.5074905, step = 800 (10.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.26456\n",
            "I0124 08:49:36.472390 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.26456\n",
            "INFO:tensorflow:loss = 0.5469808, step = 900 (10.793 sec)\n",
            "I0124 08:49:36.473248 139920538380160 basic_session_run_hooks.py:260] loss = 0.5469808, step = 900 (10.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.31278\n",
            "I0124 08:49:47.210289 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.31278\n",
            "INFO:tensorflow:loss = 0.41271442, step = 1000 (10.738 sec)\n",
            "I0124 08:49:47.211292 139920538380160 basic_session_run_hooks.py:260] loss = 0.41271442, step = 1000 (10.738 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.09698\n",
            "I0124 08:49:58.202929 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.09698\n",
            "INFO:tensorflow:loss = 0.61447644, step = 1100 (10.993 sec)\n",
            "I0124 08:49:58.203938 139920538380160 basic_session_run_hooks.py:260] loss = 0.61447644, step = 1100 (10.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.33644\n",
            "I0124 08:50:08.913756 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.33644\n",
            "INFO:tensorflow:loss = 0.49054852, step = 1200 (10.711 sec)\n",
            "I0124 08:50:08.914820 139920538380160 basic_session_run_hooks.py:260] loss = 0.49054852, step = 1200 (10.711 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.32393\n",
            "I0124 08:50:19.638740 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.32393\n",
            "INFO:tensorflow:loss = 0.15790263, step = 1300 (10.725 sec)\n",
            "I0124 08:50:19.640117 139920538380160 basic_session_run_hooks.py:260] loss = 0.15790263, step = 1300 (10.725 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.33134\n",
            "I0124 08:50:30.355342 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.33134\n",
            "INFO:tensorflow:loss = 0.4754283, step = 1400 (10.716 sec)\n",
            "I0124 08:50:30.356223 139920538380160 basic_session_run_hooks.py:260] loss = 0.4754283, step = 1400 (10.716 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.30201\n",
            "I0124 08:50:41.105665 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.30201\n",
            "INFO:tensorflow:loss = 0.32163194, step = 1500 (10.750 sec)\n",
            "I0124 08:50:41.106620 139920538380160 basic_session_run_hooks.py:260] loss = 0.32163194, step = 1500 (10.750 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.21595\n",
            "I0124 08:50:51.956472 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.21595\n",
            "INFO:tensorflow:loss = 0.12789497, step = 1600 (10.851 sec)\n",
            "I0124 08:50:51.957426 139920538380160 basic_session_run_hooks.py:260] loss = 0.12789497, step = 1600 (10.851 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.24044\n",
            "I0124 08:51:02.778480 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.24044\n",
            "INFO:tensorflow:loss = 0.33711612, step = 1700 (10.823 sec)\n",
            "I0124 08:51:02.780493 139920538380160 basic_session_run_hooks.py:260] loss = 0.33711612, step = 1700 (10.823 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.29294\n",
            "I0124 08:51:13.539318 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.29294\n",
            "INFO:tensorflow:loss = 0.35385254, step = 1800 (10.760 sec)\n",
            "I0124 08:51:13.540449 139920538380160 basic_session_run_hooks.py:260] loss = 0.35385254, step = 1800 (10.760 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.32405\n",
            "I0124 08:51:24.264281 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.32405\n",
            "INFO:tensorflow:loss = 0.29506513, step = 1900 (10.725 sec)\n",
            "I0124 08:51:24.265202 139920538380160 basic_session_run_hooks.py:260] loss = 0.29506513, step = 1900 (10.725 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.25119\n",
            "I0124 08:51:35.073706 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.25119\n",
            "INFO:tensorflow:loss = 0.34046692, step = 2000 (10.810 sec)\n",
            "I0124 08:51:35.075184 139920538380160 basic_session_run_hooks.py:260] loss = 0.34046692, step = 2000 (10.810 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.29271\n",
            "I0124 08:51:45.834825 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.29271\n",
            "INFO:tensorflow:loss = 0.13130952, step = 2100 (10.761 sec)\n",
            "I0124 08:51:45.835963 139920538380160 basic_session_run_hooks.py:260] loss = 0.13130952, step = 2100 (10.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.23033\n",
            "I0124 08:51:56.668672 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.23033\n",
            "INFO:tensorflow:loss = 0.12957479, step = 2200 (10.834 sec)\n",
            "I0124 08:51:56.669890 139920538380160 basic_session_run_hooks.py:260] loss = 0.12957479, step = 2200 (10.834 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.30043\n",
            "I0124 08:52:07.420833 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.30043\n",
            "INFO:tensorflow:loss = 0.16077079, step = 2300 (10.752 sec)\n",
            "I0124 08:52:07.421767 139920538380160 basic_session_run_hooks.py:260] loss = 0.16077079, step = 2300 (10.752 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.24103\n",
            "I0124 08:52:18.242233 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.24103\n",
            "INFO:tensorflow:loss = 0.15412728, step = 2400 (10.822 sec)\n",
            "I0124 08:52:18.243464 139920538380160 basic_session_run_hooks.py:260] loss = 0.15412728, step = 2400 (10.822 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.14848\n",
            "I0124 08:52:29.172965 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.14848\n",
            "INFO:tensorflow:loss = 0.27131405, step = 2500 (10.931 sec)\n",
            "I0124 08:52:29.174020 139920538380160 basic_session_run_hooks.py:260] loss = 0.27131405, step = 2500 (10.931 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.25704\n",
            "I0124 08:52:39.975522 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.25704\n",
            "INFO:tensorflow:loss = 0.13503312, step = 2600 (10.803 sec)\n",
            "I0124 08:52:39.976682 139920538380160 basic_session_run_hooks.py:260] loss = 0.13503312, step = 2600 (10.803 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.24343\n",
            "I0124 08:52:50.794068 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.24343\n",
            "INFO:tensorflow:loss = 0.1204611, step = 2700 (10.819 sec)\n",
            "I0124 08:52:50.795206 139920538380160 basic_session_run_hooks.py:260] loss = 0.1204611, step = 2700 (10.819 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.25462\n",
            "I0124 08:53:01.599428 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.25462\n",
            "INFO:tensorflow:loss = 0.045222152, step = 2800 (10.805 sec)\n",
            "I0124 08:53:01.600226 139920538380160 basic_session_run_hooks.py:260] loss = 0.045222152, step = 2800 (10.805 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.35889\n",
            "I0124 08:53:12.284449 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.35889\n",
            "INFO:tensorflow:loss = 0.23577797, step = 2900 (10.685 sec)\n",
            "I0124 08:53:12.285610 139920538380160 basic_session_run_hooks.py:260] loss = 0.23577797, step = 2900 (10.685 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.22968\n",
            "I0124 08:53:23.119098 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.22968\n",
            "INFO:tensorflow:loss = 0.19899908, step = 3000 (10.835 sec)\n",
            "I0124 08:53:23.120279 139920538380160 basic_session_run_hooks.py:260] loss = 0.19899908, step = 3000 (10.835 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.25293\n",
            "I0124 08:53:33.926474 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.25293\n",
            "INFO:tensorflow:loss = 0.12886192, step = 3100 (10.807 sec)\n",
            "I0124 08:53:33.927746 139920538380160 basic_session_run_hooks.py:260] loss = 0.12886192, step = 3100 (10.807 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.26712\n",
            "I0124 08:53:44.717276 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.26712\n",
            "INFO:tensorflow:loss = 0.044988234, step = 3200 (10.791 sec)\n",
            "I0124 08:53:44.718707 139920538380160 basic_session_run_hooks.py:260] loss = 0.044988234, step = 3200 (10.791 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.2769\n",
            "I0124 08:53:55.496774 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.2769\n",
            "INFO:tensorflow:loss = 0.10323679, step = 3300 (10.779 sec)\n",
            "I0124 08:53:55.497967 139920538380160 basic_session_run_hooks.py:260] loss = 0.10323679, step = 3300 (10.779 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.20101\n",
            "I0124 08:54:06.365190 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.20101\n",
            "INFO:tensorflow:loss = 0.06333749, step = 3400 (10.868 sec)\n",
            "I0124 08:54:06.366177 139920538380160 basic_session_run_hooks.py:260] loss = 0.06333749, step = 3400 (10.868 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.33899\n",
            "I0124 08:54:17.072891 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.33899\n",
            "INFO:tensorflow:loss = 0.36720824, step = 3500 (10.708 sec)\n",
            "I0124 08:54:17.073950 139920538380160 basic_session_run_hooks.py:260] loss = 0.36720824, step = 3500 (10.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.38\n",
            "I0124 08:54:27.733899 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.38\n",
            "INFO:tensorflow:loss = 0.08766049, step = 3600 (10.661 sec)\n",
            "I0124 08:54:27.735156 139920538380160 basic_session_run_hooks.py:260] loss = 0.08766049, step = 3600 (10.661 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.21874\n",
            "I0124 08:54:38.581373 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.21874\n",
            "INFO:tensorflow:loss = 0.098984376, step = 3700 (10.847 sec)\n",
            "I0124 08:54:38.582314 139920538380160 basic_session_run_hooks.py:260] loss = 0.098984376, step = 3700 (10.847 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.33777\n",
            "I0124 08:54:49.290633 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.33777\n",
            "INFO:tensorflow:loss = 0.11766191, step = 3800 (10.710 sec)\n",
            "I0124 08:54:49.291989 139920538380160 basic_session_run_hooks.py:260] loss = 0.11766191, step = 3800 (10.710 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.18758\n",
            "I0124 08:55:00.174874 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.18758\n",
            "INFO:tensorflow:loss = 0.07453996, step = 3900 (10.884 sec)\n",
            "I0124 08:55:00.176135 139920538380160 basic_session_run_hooks.py:260] loss = 0.07453996, step = 3900 (10.884 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.17358\n",
            "I0124 08:55:11.075721 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.17358\n",
            "INFO:tensorflow:loss = 0.08496243, step = 4000 (10.901 sec)\n",
            "I0124 08:55:11.076879 139920538380160 basic_session_run_hooks.py:260] loss = 0.08496243, step = 4000 (10.901 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.24126\n",
            "I0124 08:55:21.896744 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.24126\n",
            "INFO:tensorflow:loss = 0.045319192, step = 4100 (10.821 sec)\n",
            "I0124 08:55:21.897958 139920538380160 basic_session_run_hooks.py:260] loss = 0.045319192, step = 4100 (10.821 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.22158\n",
            "I0124 08:55:32.740858 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.22158\n",
            "INFO:tensorflow:loss = 0.26049086, step = 4200 (10.844 sec)\n",
            "I0124 08:55:32.741792 139920538380160 basic_session_run_hooks.py:260] loss = 0.26049086, step = 4200 (10.844 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.23634\n",
            "I0124 08:55:43.567676 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.23634\n",
            "INFO:tensorflow:loss = 0.13473855, step = 4300 (10.827 sec)\n",
            "I0124 08:55:43.568567 139920538380160 basic_session_run_hooks.py:260] loss = 0.13473855, step = 4300 (10.827 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.22906\n",
            "I0124 08:55:54.403072 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.22906\n",
            "INFO:tensorflow:loss = 0.14734864, step = 4400 (10.838 sec)\n",
            "I0124 08:55:54.406102 139920538380160 basic_session_run_hooks.py:260] loss = 0.14734864, step = 4400 (10.838 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.29744\n",
            "I0124 08:56:05.158664 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.29744\n",
            "INFO:tensorflow:loss = 0.08707797, step = 4500 (10.754 sec)\n",
            "I0124 08:56:05.159679 139920538380160 basic_session_run_hooks.py:260] loss = 0.08707797, step = 4500 (10.754 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.2883\n",
            "I0124 08:56:15.924912 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.2883\n",
            "INFO:tensorflow:loss = 0.09551896, step = 4600 (10.767 sec)\n",
            "I0124 08:56:15.926264 139920538380160 basic_session_run_hooks.py:260] loss = 0.09551896, step = 4600 (10.767 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.17811\n",
            "I0124 08:56:26.820492 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.17811\n",
            "INFO:tensorflow:loss = 0.26969653, step = 4700 (10.895 sec)\n",
            "I0124 08:56:26.821697 139920538380160 basic_session_run_hooks.py:260] loss = 0.26969653, step = 4700 (10.895 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.37342\n",
            "I0124 08:56:37.488857 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.37342\n",
            "INFO:tensorflow:loss = 0.07981849, step = 4800 (10.668 sec)\n",
            "I0124 08:56:37.489877 139920538380160 basic_session_run_hooks.py:260] loss = 0.07981849, step = 4800 (10.668 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.25647\n",
            "I0124 08:56:48.292115 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.25647\n",
            "INFO:tensorflow:loss = 0.069804385, step = 4900 (10.803 sec)\n",
            "I0124 08:56:48.293107 139920538380160 basic_session_run_hooks.py:260] loss = 0.069804385, step = 4900 (10.803 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.13778\n",
            "I0124 08:56:59.235770 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.13778\n",
            "INFO:tensorflow:loss = 0.074705705, step = 5000 (10.944 sec)\n",
            "I0124 08:56:59.237562 139920538380160 basic_session_run_hooks.py:260] loss = 0.074705705, step = 5000 (10.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.37854\n",
            "I0124 08:57:09.898437 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.37854\n",
            "INFO:tensorflow:loss = 0.1275184, step = 5100 (10.662 sec)\n",
            "I0124 08:57:09.899785 139920538380160 basic_session_run_hooks.py:260] loss = 0.1275184, step = 5100 (10.662 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.22845\n",
            "I0124 08:57:20.734393 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.22845\n",
            "INFO:tensorflow:loss = 0.085959315, step = 5200 (10.836 sec)\n",
            "I0124 08:57:20.736129 139920538380160 basic_session_run_hooks.py:260] loss = 0.085959315, step = 5200 (10.836 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.19593\n",
            "I0124 08:57:31.608766 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.19593\n",
            "INFO:tensorflow:loss = 0.08488754, step = 5300 (10.874 sec)\n",
            "I0124 08:57:31.609829 139920538380160 basic_session_run_hooks.py:260] loss = 0.08488754, step = 5300 (10.874 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.34079\n",
            "I0124 08:57:42.314485 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.34079\n",
            "INFO:tensorflow:loss = 0.094796225, step = 5400 (10.706 sec)\n",
            "I0124 08:57:42.315472 139920538380160 basic_session_run_hooks.py:260] loss = 0.094796225, step = 5400 (10.706 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5409 into training/model.ckpt.\n",
            "I0124 08:57:43.192984 139920538380160 basic_session_run_hooks.py:606] Saving checkpoints for 5409 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0124 08:57:45.650975 139920538380160 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 08:57:47.472095 139920538380160 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 08:57:47.488921 139920538380160 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0124 08:57:47.489326 139920538380160 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 08:57:48.903355 139920538380160 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 08:57:48.923939 139920538380160 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0124 08:57:49.686316 139920538380160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0124 08:57:50.662807 139920538380160 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0124 08:57:50.936728 139920538380160 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0124 08:57:51.121813 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0124 08:57:51.222024 139920538380160 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0124 08:57:51.633043 139920538380160 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-01-24T08:57:51Z\n",
            "I0124 08:57:51.653458 139920538380160 evaluation.py:255] Starting evaluation at 2020-01-24T08:57:51Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0124 08:57:52.247984 139920538380160 monitored_session.py:240] Graph was finalized.\n",
            "2020-01-24 08:57:52.249087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:57:52.249644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-24 08:57:52.249783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-24 08:57:52.249823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-24 08:57:52.249854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-24 08:57:52.249884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-24 08:57:52.249910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-24 08:57:52.249967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-24 08:57:52.250065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-24 08:57:52.250215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:57:52.250895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:57:52.251416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-24 08:57:52.251501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-01-24 08:57:52.251519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-01-24 08:57:52.251530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-01-24 08:57:52.251672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:57:52.252238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 08:57:52.252695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5409\n",
            "I0124 08:57:52.254392 139920538380160 saver.py:1284] Restoring parameters from training/model.ckpt-5409\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0124 08:57:53.499773 139920538380160 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0124 08:57:53.669126 139920538380160 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 72 images.\n",
            "I0124 08:58:03.675526 139916843570944 coco_evaluation.py:205] Performing evaluation on 72 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0124 08:58:03.678330 139916843570944 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0124 08:58:03.690335 139916843570944 coco_tools.py:137] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.29s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.970\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.871\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.789\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791\n",
            "INFO:tensorflow:Finished evaluation at 2020-01-24-08:58:05\n",
            "I0124 08:58:05.242405 139920538380160 evaluation.py:275] Finished evaluation at 2020-01-24-08:58:05\n",
            "INFO:tensorflow:Saving dict for global step 5409: DetectionBoxes_Precision/mAP = 0.7296998, DetectionBoxes_Precision/mAP (large) = 0.73110354, DetectionBoxes_Precision/mAP (medium) = 0.75, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9695022, DetectionBoxes_Precision/mAP@.75IOU = 0.87147486, DetectionBoxes_Recall/AR@1 = 0.69760466, DetectionBoxes_Recall/AR@10 = 0.78905755, DetectionBoxes_Recall/AR@100 = 0.7903415, DetectionBoxes_Recall/AR@100 (large) = 0.7911945, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14598559, Loss/BoxClassifierLoss/localization_loss = 0.0876955, Loss/RPNLoss/localization_loss = 0.16308327, Loss/RPNLoss/objectness_loss = 0.22957669, Loss/total_loss = 0.6263411, global_step = 5409, learning_rate = 0.0002, loss = 0.6263411\n",
            "I0124 08:58:05.242748 139920538380160 estimator.py:2049] Saving dict for global step 5409: DetectionBoxes_Precision/mAP = 0.7296998, DetectionBoxes_Precision/mAP (large) = 0.73110354, DetectionBoxes_Precision/mAP (medium) = 0.75, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9695022, DetectionBoxes_Precision/mAP@.75IOU = 0.87147486, DetectionBoxes_Recall/AR@1 = 0.69760466, DetectionBoxes_Recall/AR@10 = 0.78905755, DetectionBoxes_Recall/AR@100 = 0.7903415, DetectionBoxes_Recall/AR@100 (large) = 0.7911945, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.14598559, Loss/BoxClassifierLoss/localization_loss = 0.0876955, Loss/RPNLoss/localization_loss = 0.16308327, Loss/RPNLoss/objectness_loss = 0.22957669, Loss/total_loss = 0.6263411, global_step = 5409, learning_rate = 0.0002, loss = 0.6263411\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5409: training/model.ckpt-5409\n",
            "I0124 08:58:06.301658 139920538380160 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5409: training/model.ckpt-5409\n",
            "INFO:tensorflow:global_step/sec: 2.94366\n",
            "I0124 08:58:16.285735 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 2.94366\n",
            "INFO:tensorflow:loss = 0.12533784, step = 5500 (33.972 sec)\n",
            "I0124 08:58:16.287264 139920538380160 basic_session_run_hooks.py:260] loss = 0.12533784, step = 5500 (33.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.13589\n",
            "I0124 08:58:27.231546 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.13589\n",
            "INFO:tensorflow:loss = 0.03217214, step = 5600 (10.945 sec)\n",
            "I0124 08:58:27.232656 139920538380160 basic_session_run_hooks.py:260] loss = 0.03217214, step = 5600 (10.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.24814\n",
            "I0124 08:58:38.044590 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.24814\n",
            "INFO:tensorflow:loss = 0.056933206, step = 5700 (10.813 sec)\n",
            "I0124 08:58:38.045796 139920538380160 basic_session_run_hooks.py:260] loss = 0.056933206, step = 5700 (10.813 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.23308\n",
            "I0124 08:58:48.875247 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.23308\n",
            "INFO:tensorflow:loss = 0.36685738, step = 5800 (10.830 sec)\n",
            "I0124 08:58:48.876260 139920538380160 basic_session_run_hooks.py:260] loss = 0.36685738, step = 5800 (10.830 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.18022\n",
            "I0124 08:58:59.768195 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.18022\n",
            "INFO:tensorflow:loss = 0.06240799, step = 5900 (10.893 sec)\n",
            "I0124 08:58:59.769215 139920538380160 basic_session_run_hooks.py:260] loss = 0.06240799, step = 5900 (10.893 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.32138\n",
            "I0124 08:59:10.496294 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.32138\n",
            "INFO:tensorflow:loss = 0.089264646, step = 6000 (10.728 sec)\n",
            "I0124 08:59:10.497269 139920538380160 basic_session_run_hooks.py:260] loss = 0.089264646, step = 6000 (10.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.26525\n",
            "I0124 08:59:21.289246 139920538380160 basic_session_run_hooks.py:692] global_step/sec: 9.26525\n",
            "INFO:tensorflow:loss = 0.11502648, step = 6100 (10.793 sec)\n",
            "I0124 08:59:21.290440 139920538380160 basic_session_run_hooks.py:260] loss = 0.11502648, step = 6100 (10.793 sec)\n",
            "Traceback (most recent call last):\n",
            "  File \"object_detection/model_main.py\", line 109, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"object_detection/model_main.py\", line 105, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEreBja7FXp1",
        "colab_type": "text"
      },
      "source": [
        "# exporting the model inference graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIEaIf9LEaOc",
        "colab_type": "code",
        "outputId": "e26649fc-66b0-4421-9952-3d1ddfd7c8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# exporting our model \n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research/\n",
        "\n",
        "\n",
        "#dir where the model will be saved\n",
        "output_directory = './drive/My\\ Drive/{0}/models/research/fine_tuned_model'.format(maindirectory)\n",
        "\n",
        "lst = os.listdir('training')\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join('./drive/My\\ Drive/{0}/models/research'.format(maindirectory),'training', last_model)\n",
        "print(last_model_path)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n",
            "./drive/My\\ Drive/my_detector2/models/research/training/model.ckpt-5409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LOCMMgAjGmJ",
        "colab_type": "code",
        "outputId": "2ef49cf5-c6ef-4b45-b49b-6e8fcdd949a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# command to export the model as frozen inference graph \n",
        "# we can use this frozen inference graph only for inference not for training \n",
        "# we can export saved_model.pb however which we can use to resume training \n",
        "%cd /content\n",
        "!python ./drive/'My Drive'/$maindirectory/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=./drive/My\\ Drive/$maindirectory/models/research/object_detection/samples/configs/$configfilename \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From ./drive/My Drive/my_detector2/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From ./drive/My Drive/my_detector2/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0124 09:02:04.873927 140438761895808 module_wrapper.py:139] From ./drive/My Drive/my_detector2/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0124 09:02:04.883853 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0124 09:02:04.884402 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0124 09:02:04.938294 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0124 09:02:05.000241 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0124 09:02:05.012217 140438761895808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0124 09:02:06.783429 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 09:02:06.792103 140438761895808 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0124 09:02:06.792567 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 09:02:06.809789 140438761895808 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0124 09:02:06.810192 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0124 09:02:06.810323 140438761895808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0124 09:02:06.879634 140438761895808 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0124 09:02:07.594510 140438761895808 deprecation.py:506] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0124 09:02:07.616706 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0124 09:02:08.356907 140438761895808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 09:02:08.364177 140438761895808 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 09:02:08.389718 140438761895808 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0124 09:02:09.340102 140438761895808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0124 09:02:09.778661 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0124 09:02:09.778984 140438761895808 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0124 09:02:09.782662 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0124 09:02:09.782826 140438761895808 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0124 09:02:09.784301 140438761895808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "242 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/12.87m params)\n",
            "  Conv (--/2.65m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/4.25m params)\n",
            "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "  SecondStageBoxPredictor (--/31.77k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/24.60k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x24, 24.58k/24.58k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/7.17k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (7, 7/7 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (1024x7, 7.17k/7.17k params)\n",
            "  SecondStageFeatureExtractor (--/5.89m params)\n",
            "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "242 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/6.18k flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0124 09:02:11.354075 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0124 09:02:12.561753 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-01-24 09:02:12.563511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-01-24 09:02:12.566790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:12.567752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-24 09:02:12.568194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-24 09:02:12.570341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-24 09:02:12.572195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-24 09:02:12.572538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-24 09:02:12.574592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-24 09:02:12.575522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-24 09:02:12.579795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-24 09:02:12.579971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:12.580843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:12.581643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-24 09:02:12.587785: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-01-24 09:02:12.588024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x210af40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-24 09:02:12.588088: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-01-24 09:02:12.680000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:12.681022: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x210b480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-24 09:02:12.681103: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-01-24 09:02:12.681287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:12.681986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-24 09:02:12.682084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-24 09:02:12.682119: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-24 09:02:12.682146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-24 09:02:12.682169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-24 09:02:12.682191: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-24 09:02:12.682216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-24 09:02:12.682241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-24 09:02:12.682337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:12.683170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:12.684111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-24 09:02:12.684212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-24 09:02:12.685819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-01-24 09:02:12.685862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-01-24 09:02:12.685874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-01-24 09:02:12.686059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:12.686935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:12.687878: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-01-24 09:02:12.687922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from ./drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "I0124 09:02:12.690839 140438761895808 saver.py:1284] Restoring parameters from ./drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0124 09:02:14.939547 140438761895808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-01-24 09:02:15.864973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:15.865784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-24 09:02:15.865853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-24 09:02:15.865881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-24 09:02:15.865904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-24 09:02:15.865926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-24 09:02:15.865948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-24 09:02:15.865969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-24 09:02:15.865992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-24 09:02:15.866113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:15.866977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:15.867800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-24 09:02:15.867841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-01-24 09:02:15.867855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-01-24 09:02:15.867865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-01-24 09:02:15.867971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:15.868756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:15.869537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from ./drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "I0124 09:02:15.871593 140438761895808 saver.py:1284] Restoring parameters from ./drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0124 09:02:16.701338 140438761895808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0124 09:02:16.701627 140438761895808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 356 variables.\n",
            "I0124 09:02:17.171133 140438761895808 graph_util_impl.py:334] Froze 356 variables.\n",
            "INFO:tensorflow:Converted 356 variables to const ops.\n",
            "I0124 09:02:17.308212 140438761895808 graph_util_impl.py:394] Converted 356 variables to const ops.\n",
            "2020-01-24 09:02:17.608582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:17.609525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-24 09:02:17.609624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-24 09:02:17.609655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-24 09:02:17.609698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-24 09:02:17.609722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-24 09:02:17.609744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-24 09:02:17.609769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-24 09:02:17.609810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-24 09:02:17.609944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:17.610860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:17.611811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-24 09:02:17.611852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-01-24 09:02:17.611866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-01-24 09:02:17.611875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-01-24 09:02:17.611980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:17.612903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-24 09:02:17.613805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0124 09:02:18.209696 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0124 09:02:18.212122 140438761895808 deprecation.py:323] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0124 09:02:18.212603 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0124 09:02:18.212806 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0124 09:02:18.213096 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "W0124 09:02:18.213290 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0124 09:02:18.213586 140438761895808 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0124 09:02:18.213706 140438761895808 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./drive/My Drive/my_detector2/models/research/fine_tuned_model/saved_model/saved_model.pb\n",
            "I0124 09:02:18.770926 140438761895808 builder_impl.py:425] SavedModel written to: ./drive/My Drive/my_detector2/models/research/fine_tuned_model/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0124 09:02:18.816199 140438761895808 module_wrapper.py:139] From /content/drive/My Drive/my_detector/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to ./drive/My Drive/my_detector2/models/research/fine_tuned_model/pipeline.config\n",
            "I0124 09:02:18.816429 140438761895808 config_util.py:190] Writing pipeline config file to ./drive/My Drive/my_detector2/models/research/fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF5GXyuTF5QL",
        "colab_type": "text"
      },
      "source": [
        "# start inference \n",
        "\n",
        "[notebook importing the graph / making an inference](https://colab.research.google.com/drive/1yuZqWmV1FcTcaTcf4w7W16pYkBHyqsvJ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re0NsWufBvzM",
        "colab_type": "text"
      },
      "source": [
        "# downloading the graph / labelmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuXYJLCWkqTG",
        "colab_type": "code",
        "outputId": "3b754577-e849-4fa1-b58b-b1cf21ac96af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "#downloads the frozen model that is needed for inference\n",
        "# output_directory = 'fine_tuned_model' dir specified above.\n",
        "\n",
        "files.download('/content/drive/My Drive/{0}/models/research/fine_tuned_model'.format(maindirectory) + '/frozen_inference_graph.pb')\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 44586, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 351, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 364, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 724, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 803, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFunAagymMBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('/content/drive/My Drive/{0}/data'.format(maindirectory) + '/label_map.pbtxt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2ItvNqU5yJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('/content/drive/My Drive/{0}/models/research/fine_tuned_model/saved_model'.format(maindirectory) + '/saved_model.pb')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN_j5P6POD_m",
        "colab_type": "text"
      },
      "source": [
        "# non working code pieces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI89uiMlma_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/'My Drive'/$maindirectory\n",
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "from object_detection.utils import dataset_util\n",
        "\n",
        "\n",
        "#change this to the base directory where your data/ is \n",
        "data_base_url = \"/content/drive/My Drive/{}/data/images/\".format(maindirectory)\n",
        "\n",
        "#location of images\n",
        "image_dir = data_base_url +'images/'\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "  if row_label == 'pistol':\n",
        "    return 1\n",
        "  else:\n",
        "    None\n",
        "\n",
        "def split(df, group):\n",
        "  data = namedtuple('data', ['filename', 'object'])\n",
        "  gb = df.groupby(group)\n",
        "  return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "    encoded_jpg = fid.read()\n",
        "  encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "  image = Image.open(encoded_jpg_io)\n",
        "  width, height = image.size\n",
        "  filename = group.filename.encode('utf8')\n",
        "  image_format = b'jpg'\n",
        "  xmins = []\n",
        "  xmaxs = []\n",
        "  ymins = []\n",
        "  ymaxs = []\n",
        "  classes_text = []\n",
        "  classes = []\n",
        "  for index, row in group.object.iterrows():\n",
        "    xmins.append(row['xmin'] / width)\n",
        "    xmaxs.append(row['xmax'] / width)\n",
        "    ymins.append(row['ymin'] / height)\n",
        "    ymaxs.append(row['ymax'] / height)\n",
        "    classes_text.append(row['class'].encode('utf8'))\n",
        "    classes.append(class_text_to_int(row['class']))\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "    'image/height': dataset_util.int64_feature(height),\n",
        "    'image/width': dataset_util.int64_feature(width),\n",
        "    'image/filename': dataset_util.bytes_feature(filename),\n",
        "    'image/source_id': dataset_util.bytes_feature(filename),\n",
        "    'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "    'image/format': dataset_util.bytes_feature(image_format),\n",
        "    'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "    'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "    'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "    'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "    'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "    'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "#creates tfrecord for both csv's\n",
        "\n",
        "for csv in ['train_labels', 'test_labels']:\n",
        "  writer = tf.io.TFRecordWriter(data_base_url + csv + '.record')\n",
        "  path = os.path.join(image_dir)\n",
        "  examples = pd.read_csv(data_base_url + csv + '.csv')\n",
        "  grouped = split(examples, 'filename')\n",
        "  for group in grouped:\n",
        "    tf_example = create_tf_example(group, path)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "    \n",
        "  writer.close()\n",
        "  output_path = os.path.join(os.getcwd(), data_base_url + csv + '.record')\n",
        "  print('Successfully created the TFRecords: {}'.format(data_base_url +csv + '.record'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-GTuOrIB4lW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#path to the config file\n",
        "%%writefile object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n",
        "\n",
        "# paste the content of the config file in the same cell here.\n",
        "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 6\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 1\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00004\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v2'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00004\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000\n",
        "        iou_threshold: 0.99\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 24\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.004\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "  fine_tune_checkpoint: \"/content/drive/My Drive/my_detector/models/research/pretrained_model/model.ckpt\"\n",
        "  fine_tune_checkpoint_type:  \"detection\"\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 10000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/drive/My Drive/my_detector/data/train.record\"\n",
        "  }\n",
        "  label_map_path: \"/content/drive/My Drive/my_detector/data/label_map.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  num_examples: 32\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  max_evals: 7\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/drive/My Drive/my_detector/data/test.record\"\n",
        "  }\n",
        "  label_map_path: \"/content/drive/My Drive/my_detector/data/label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}