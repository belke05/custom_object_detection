{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "export_for_production.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuD_0b7a0lTs",
        "colab_type": "text"
      },
      "source": [
        "#config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ9YMai2T7LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os, numpy as np, tensorflow as tf, re\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "maindirectory = 'my_detector2'\n",
        "configfilename = 'faster_rcnn_inception_v2_pets.config'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoEychV_XoqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a17e114-fec6-44b6-8e3c-372ae0197382"
      },
      "source": [
        "# compile into py files\n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!python setup.py build\n",
        "!python setup.py install"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n",
            "running build\n",
            "running build_py\n",
            "copying object_detection/updated_exporter.py -> build/lib/object_detection\n",
            "copying object_detection/protos/anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/argmax_matcher_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/bipartite_matcher_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/box_predictor_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/calibration_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/eval_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/losses_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/train_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/faster_rcnn_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/matcher_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/graph_rewriter_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/mean_stddev_box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/model_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/hyperparams_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/multiscale_anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/image_resizer_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/optimizer_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/input_reader_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/pipeline_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/keypoint_box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/post_processing_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/preprocessor_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/region_similarity_calculator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/square_box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/ssd_anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/ssd_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/string_int_label_map_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/target_assigner_pb2.py -> build/lib/object_detection/protos\n",
            "running egg_info\n",
            "writing object_detection.egg-info/PKG-INFO\n",
            "writing dependency_links to object_detection.egg-info/dependency_links.txt\n",
            "writing requirements to object_detection.egg-info/requires.txt\n",
            "writing top-level names to object_detection.egg-info/top_level.txt\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing object_detection.egg-info/PKG-INFO\n",
            "writing dependency_links to object_detection.egg-info/dependency_links.txt\n",
            "writing requirements to object_detection.egg-info/requires.txt\n",
            "writing top-level names to object_detection.egg-info/top_level.txt\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/README.md -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/__init__.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/CONTRIBUTING.md -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/export_tflite_ssd_graph_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/inputs_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/export_tflite_ssd_graph_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/inputs.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/export_tflite_ssd_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/export_inference_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/eval_util_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/eval_util.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/exporter.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/exporter_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/model_lib_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/model_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/model_main.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/model_lib_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/model_hparams.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/model_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/object_detection_tutorial.ipynb -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/model_tpu_main.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/faster_rcnn_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/square_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/mean_stddev_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/square_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/keypoint_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/keypoint_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/mean_stddev_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/hyperparams_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/calibration_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/box_coder_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/anchor_generator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/calibration_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/dataset_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/target_assigner_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/matcher_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/box_coder_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/anchor_generator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/model_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/hyperparams_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/losses_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/optimizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/image_resizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/preprocessor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/graph_rewriter_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/optimizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/losses_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/box_predictor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/box_predictor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/matcher_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/post_processing_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/preprocessor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/region_similarity_calculator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/graph_rewriter_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/dataset_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/image_resizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/model_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/region_similarity_calculator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/input_reader_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/input_reader_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/target_assigner_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/post_processing_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/freezable_batch_norm_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/preprocessor_cache.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/data_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/matcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/region_similarity_calculator_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/keypoint_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/balanced_positive_negative_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/freezable_batch_norm.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/losses.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/model.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/batcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/post_processing.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/preprocessor_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/minibatch_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/losses_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/prefetcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/balanced_positive_negative_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/prefetcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/batch_multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/minibatch_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/standard_fields.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/target_assigner_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/batcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/target_assigner.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/class_agnostic_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/keypoint_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/preprocessor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/data_parser.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/region_similarity_calculator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_list.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/data_decoders\n",
            "copying build/lib/object_detection/data_decoders/tf_example_decoder_test.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n",
            "copying build/lib/object_detection/data_decoders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n",
            "copying build/lib/object_detection/data_decoders/tf_example_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_coco_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_kitti_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_pascal_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/tf_record_creation_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_coco_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/tf_record_creation_util.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/download_and_preprocess_mscoco.sh -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_pet_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_pycocotools_package.sh -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_oid_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "copying build/lib/object_detection/inference/detection_inference_test.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "copying build/lib/object_detection/inference/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "copying build/lib/object_detection/inference/detection_inference.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "copying build/lib/object_detection/inference/infer_detections.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/eval.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/evaluator.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/trainer_test.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/trainer.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/train.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/argmax_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/bipartite_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/bipartite_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/argmax_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/rfcn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/ssd_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/coco_tools_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/coco_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/tf_example_parser_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/calibration_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/coco_tools.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/calibration_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/coco_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/tf_example_parser.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/calibration_metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/offline_eval_map_corloc.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/calibration_metrics.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/io_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/offline_eval_map_corloc_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/feature_map_generators.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/feature_map_generators_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/mobilenet_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/resnet_v1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/inception_resnet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/inception_resnet_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/model_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/mobilenet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/resnet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/mobilenet_v1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models\n",
            "copying build/lib/object_detection/models/keras_models/base_models/original_mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/convolutional_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/convolutional_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/convolutional_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/convolutional_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/rfcn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/mask_rcnn_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/mask_rcnn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/rfcn_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/rfcn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/rfcn_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_box_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/box_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/class_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_class_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keypoint_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/mask_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keypoint_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_mask_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/argmax_matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/ssd.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/bipartite_matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/image_resizer.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/region_similarity_calculator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/mean_stddev_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/train.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/string_int_label_map.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/square_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/keypoint_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/preprocessor.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/graph_rewriter.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/flexible_grid_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/hyperparams.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/faster_rcnn_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/optimizer.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/faster_rcnn.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/ssd_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/eval.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/target_assigner.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/calibration.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/losses.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/model.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/input_reader.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/post_processing.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/pipeline.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/box_predictor.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/multiscale_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/grid_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/train_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/post_processing_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/losses_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/argmax_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/bipartite_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/preprocessor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/graph_rewriter_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/region_similarity_calculator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/mean_stddev_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/square_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/box_predictor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/model_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/hyperparams_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/ssd_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/calibration_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/image_resizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/multiscale_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/eval_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/ssd_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/input_reader_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/optimizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/string_int_label_map_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/keypoint_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/pipeline_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/faster_rcnn_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/target_assigner_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/ssd.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/utils.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/faster_rcnn.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n",
            "copying build/lib/object_detection/tpu_exporters/testdata/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/faster_rcnn\n",
            "copying build/lib/object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/faster_rcnn\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/ssd\n",
            "copying build/lib/object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/ssd\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/label_map_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/context_manager.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/per_image_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/dataset_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/per_image_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/json_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/autoaugment_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_mask_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/metrics.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/category_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/model_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/object_detection_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/per_image_vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/model_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/patch_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/json_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/learning_schedules.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_mask_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/context_manager_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/label_map_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/shape_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/per_image_vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/patch_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_mask_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_mask_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/config_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/dataset_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/category_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_mask_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_mask_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/object_detection_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/learning_schedules_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/config_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/test_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/shape_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/spatial_transform_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/visualization_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/test_case.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/variables_helper.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/spatial_transform_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/variables_helper_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/visualization_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/static_shape_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/static_shape.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/oid_bbox_trainable_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/mscoco_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/kitti_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/face_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/mscoco_complete_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/ava_label_map_v2.1.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/fgvc_2854_classes_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/mscoco_minival_ids.txt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/pascal_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/oid_v4_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/pet_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n",
            "copying build/lib/object_detection/dockerfiles/android/Dockerfile -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n",
            "copying build/lib/object_detection/dockerfiles/android/README.md -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_on_cloud.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_on_mobile_tensorflowlite.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/oid_inference_and_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/faq.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/defining_your_own_model.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_notebook.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/detection_model_zoo.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/evaluation_protocols.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/exporting_models.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/instance_segmentation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/installation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_locally.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_pets.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/tpu_exporters.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/tpu_compatibility.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/preparing_inputs.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/challenge_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/using_your_own_dataset.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/configuring_jobs.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/tensorboard2.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/tensorboard.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/kites_with_segment_overlay.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/tf-od-api-logo.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/kites_detections_output.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/nongroupof_case_eval.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/example_cat.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/oxford_pet.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/dogs_detections_output.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/dataset_explorer.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/groupof_case_eval.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/samples\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/samples/cloud\n",
            "copying build/lib/object_detection/samples/cloud/cloud.yml -> build/bdist.linux-x86_64/egg/object_detection/samples/cloud\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_inception_v2_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_nas_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/rfcn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet152_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_inception_v3_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_voc07.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v3_small_320x320_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_kitti.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/rfcn_resnet101_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet152_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco_quant.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/test_ckpt\n",
            "copying build/lib/object_detection/test_ckpt/ssd_inception_v2.pb -> build/bdist.linux-x86_64/egg/object_detection/test_ckpt\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/test_data\n",
            "copying build/lib/object_detection/test_data/pets_examples.record -> build/bdist.linux-x86_64/egg/object_detection/test_data\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/test_images\n",
            "copying build/lib/object_detection/test_images/image2.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images\n",
            "copying build/lib/object_detection/test_images/image_info.txt -> build/bdist.linux-x86_64/egg/object_detection/test_images\n",
            "copying build/lib/object_detection/test_images/image1.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images\n",
            "copying build/lib/object_detection/updated_exporter.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib.py to export_tflite_ssd_graph_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs_test.py to inputs_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib_test.py to export_tflite_ssd_graph_lib_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs.py to inputs.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph.py to export_tflite_ssd_graph.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_inference_graph.py to export_inference_graph.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util_test.py to eval_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util.py to eval_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter.py to exporter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_test.py to exporter_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2_test.py to model_lib_v2_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_test.py to model_lib_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_main.py to model_main.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2.py to model_lib_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_hparams.py to model_hparams.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib.py to model_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_tpu_main.py to model_tpu_main.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py to flexible_grid_anchor_generator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py to multiscale_grid_anchor_generator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator.py to multiple_grid_anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator.py to grid_anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator.py to multiscale_grid_anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator_test.py to grid_anchor_generator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py to multiple_grid_anchor_generator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator.py to flexible_grid_anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder.py to faster_rcnn_box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder.py to square_box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder.py to mean_stddev_box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder_test.py to square_box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder.py to keypoint_box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder_test.py to keypoint_box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder_test.py to faster_rcnn_box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder_test.py to mean_stddev_box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder_test.py to hyperparams_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder_test.py to calibration_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder_test.py to box_coder_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder.py to anchor_generator_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder.py to calibration_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder_test.py to dataset_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder.py to target_assigner_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder_test.py to matcher_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder.py to box_coder_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder_test.py to anchor_generator_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_test.py to model_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder.py to hyperparams_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder_test.py to losses_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder.py to optimizer_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder.py to image_resizer_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder_test.py to preprocessor_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder.py to graph_rewriter_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder_test.py to optimizer_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder.py to losses_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder.py to box_predictor_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder_test.py to box_predictor_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder.py to matcher_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder_test.py to post_processing_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder.py to preprocessor_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder_test.py to region_similarity_calculator_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder_test.py to graph_rewriter_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder.py to dataset_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder_test.py to image_resizer_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder.py to model_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder.py to region_similarity_calculator_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder_test.py to input_reader_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder.py to input_reader_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder_test.py to target_assigner_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder.py to post_processing_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm_test.py to freezable_batch_norm_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder.py to box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder_test.py to box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_cache.py to preprocessor_cache.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/anchor_generator.py to anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_decoder.py to data_decoder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher.py to matcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator_test.py to region_similarity_calculator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops_test.py to keypoint_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler.py to balanced_positive_negative_sampler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm.py to freezable_batch_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses.py to losses.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher_test.py to batcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/post_processing.py to post_processing.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_test.py to preprocessor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler.py to minibatch_sampler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses_test.py to losses_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher_test.py to prefetcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler_test.py to balanced_positive_negative_sampler_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher.py to prefetcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batch_multiclass_nms_test.py to batch_multiclass_nms_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler_test.py to minibatch_sampler_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/standard_fields.py to standard_fields.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_predictor.py to box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher_test.py to matcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner_test.py to target_assigner_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher.py to batcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner.py to target_assigner.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops.py to box_list_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/class_agnostic_nms_test.py to class_agnostic_nms_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops_test.py to box_list_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_test.py to box_list_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops.py to keypoint_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor.py to preprocessor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/multiclass_nms_test.py to multiclass_nms_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_parser.py to data_parser.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator.py to region_similarity_calculator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list.py to box_list.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder_test.py to tf_example_decoder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder.py to tf_example_decoder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record.py to create_coco_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record.py to create_kitti_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation.py to oid_tfrecord_creation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py to oid_hierarchical_labels_expansion_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record.py to create_pascal_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util_test.py to tf_record_creation_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record_test.py to create_coco_tf_record_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util.py to tf_record_creation_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation_test.py to oid_tfrecord_creation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record_test.py to create_pascal_tf_record_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pet_tf_record.py to create_pet_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py to oid_hierarchical_labels_expansion.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record_test.py to create_kitti_tf_record_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_oid_tf_record.py to create_oid_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference_test.py to detection_inference_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference.py to detection_inference.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/infer_detections.py to infer_detections.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/eval.py to eval.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/evaluator.py to evaluator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer_test.py to trainer_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer.py to trainer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/train.py to train.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher_test.py to argmax_matcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher_test.py to bipartite_matcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher.py to bipartite_matcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher.py to argmax_matcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch.py to rfcn_meta_arch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py to faster_rcnn_meta_arch_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py to faster_rcnn_meta_arch_test_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch_test.py to rfcn_meta_arch_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py to faster_rcnn_meta_arch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test_lib.py to ssd_meta_arch_test_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch.py to ssd_meta_arch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test.py to ssd_meta_arch_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools_test.py to coco_tools_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py to oid_vrd_challenge_evaluation_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation_test.py to coco_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation.py to oid_vrd_challenge_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils_test.py to oid_challenge_evaluation_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils.py to oid_challenge_evaluation_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser_test.py to tf_example_parser_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation_test.py to calibration_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation.py to oid_challenge_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools.py to coco_tools.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation.py to calibration_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation.py to coco_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser.py to tf_example_parser.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics_test.py to calibration_metrics_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py to oid_vrd_challenge_evaluation_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc.py to offline_eval_map_corloc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics.py to calibration_metrics.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/io_utils.py to io_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc_test.py to offline_eval_map_corloc_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py to ssd_mobilenet_v1_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor_test.py to ssd_inception_v2_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py to ssd_mobilenet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py to ssd_mobilenet_v3_feature_extractor_testbase.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py to faster_rcnn_inception_resnet_v2_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py to faster_rcnn_pnas_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py to faster_rcnn_inception_resnet_v2_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py to ssd_resnet_v1_fpn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py to ssd_mobilenet_v2_fpn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py to ssd_mobilenet_v1_ppn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py to ssd_resnet_v1_ppn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor_test.py to faster_rcnn_nas_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor.py to faster_rcnn_nas_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor.py to faster_rcnn_pnas_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py to ssd_resnet_v1_fpn_feature_extractor_testbase.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py to ssd_mobilenet_v1_ppn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor.py to ssd_mobilenet_v3_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py to faster_rcnn_resnet_v1_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py to ssd_mobilenet_v2_fpn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py to faster_rcnn_inception_v2_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py to embedded_ssd_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators.py to feature_map_generators.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py to ssd_mobilenet_v2_fpn_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py to ssd_mobilenet_v1_fpn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_test.py to ssd_mobilenet_v3_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py to ssd_mobilenet_v1_fpn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py to ssd_mobilenet_v2_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor.py to ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor_test.py to ssd_inception_v3_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py to faster_rcnn_mobilenet_v1_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor_test.py to ssd_pnasnet_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py to faster_rcnn_inception_v2_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py to ssd_mobilenet_v2_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py to ssd_resnet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor.py to ssd_pnasnet_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py to ssd_mobilenet_edgetpu_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py to faster_rcnn_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_test.py to ssd_mobilenet_edgetpu_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py to embedded_ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor.py to ssd_inception_v3_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py to ssd_resnet_v1_fpn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py to ssd_resnet_v1_ppn_feature_extractor_testbase.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py to ssd_resnet_v1_ppn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor.py to ssd_mobilenet_v2_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py to ssd_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_feature_extractor_test.py to ssd_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators_test.py to feature_map_generators_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor.py to ssd_inception_v2_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py to faster_rcnn_resnet_v1_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py to ssd_mobilenet_edgetpu_feature_extractor_testbase.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2.py to mobilenet_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2_test.py to mobilenet_v2_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1_test.py to resnet_v1_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2.py to inception_resnet_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2_test.py to inception_resnet_v2_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/model_utils.py to model_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1.py to mobilenet_v1.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1.py to resnet_v1.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1_test.py to mobilenet_v1_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models/original_mobilenet_v2.py to original_mobilenet_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor.py to convolutional_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor_test.py to convolutional_keras_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor_test.py to convolutional_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor.py to convolutional_keras_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor.py to rfcn_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor_test.py to mask_rcnn_keras_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor.py to mask_rcnn_keras_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor_test.py to mask_rcnn_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor.py to mask_rcnn_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor_test.py to rfcn_keras_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor.py to rfcn_keras_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor_test.py to rfcn_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head_test.py to keras_box_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head.py to keras_class_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head_test.py to box_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head.py to keras_mask_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head.py to keras_box_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head_test.py to class_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/head.py to head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head_test.py to keras_class_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head.py to class_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head.py to box_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head_test.py to keypoint_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head_test.py to mask_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head.py to keypoint_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head.py to mask_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head_test.py to keras_mask_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/train_pb2.py to train_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/anchor_generator_pb2.py to anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/post_processing_pb2.py to post_processing_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/losses_pb2.py to losses_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/argmax_matcher_pb2.py to argmax_matcher_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/flexible_grid_anchor_generator_pb2.py to flexible_grid_anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/bipartite_matcher_pb2.py to bipartite_matcher_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/preprocessor_pb2.py to preprocessor_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/matcher_pb2.py to matcher_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/graph_rewriter_pb2.py to graph_rewriter_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/region_similarity_calculator_pb2.py to region_similarity_calculator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_coder_pb2.py to box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/grid_anchor_generator_pb2.py to grid_anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/mean_stddev_box_coder_pb2.py to mean_stddev_box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/square_box_coder_pb2.py to square_box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_predictor_pb2.py to box_predictor_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/model_pb2.py to model_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/hyperparams_pb2.py to hyperparams_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_anchor_generator_pb2.py to ssd_anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/calibration_pb2.py to calibration_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/image_resizer_pb2.py to image_resizer_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/multiscale_anchor_generator_pb2.py to multiscale_anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/eval_pb2.py to eval_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_pb2.py to ssd_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/input_reader_pb2.py to input_reader_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/optimizer_pb2.py to optimizer_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_box_coder_pb2.py to faster_rcnn_box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/string_int_label_map_pb2.py to string_int_label_map_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/keypoint_box_coder_pb2.py to keypoint_box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/pipeline_pb2.py to pipeline_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_pb2.py to faster_rcnn_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/target_assigner_pb2.py to target_assigner_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/ssd.py to ssd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils_test.py to utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu.py to export_saved_model_tpu.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib.py to export_saved_model_tpu_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py to export_saved_model_tpu_lib_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/faster_rcnn.py to faster_rcnn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util_test.py to label_map_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager.py to context_manager.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation_test.py to per_image_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util_test.py to dataset_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list.py to np_box_list.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation.py to per_image_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils_test.py to json_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/autoaugment_utils.py to autoaugment_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list.py to np_box_mask_list.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics.py to metrics.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops.py to ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops.py to np_box_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops.py to np_box_list_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util.py to category_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util.py to model_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation.py to object_detection_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation_test.py to per_image_vrd_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util_test.py to model_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops_test.py to patch_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils.py to json_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules.py to learning_schedules.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops_test.py to np_mask_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops_test.py to ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager_test.py to context_manager_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util.py to label_map_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils.py to shape_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops_test.py to np_box_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops_test.py to np_box_list_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation.py to per_image_vrd_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_test.py to np_box_list_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops.py to patch_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_test.py to np_box_mask_list_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics_test.py to metrics_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops_test.py to np_box_mask_list_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util.py to config_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util.py to dataset_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util_test.py to category_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops.py to np_box_mask_list_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops.py to np_mask_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation_test.py to object_detection_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules_test.py to learning_schedules_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util_test.py to config_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils_test.py to test_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils_test.py to shape_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops.py to spatial_transform_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils_test.py to visualization_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_case.py to test_case.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper.py to variables_helper.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation.py to vrd_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation_test.py to vrd_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops_test.py to spatial_transform_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper_test.py to variables_helper_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils.py to visualization_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape_test.py to static_shape_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape.py to static_shape.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/updated_exporter.py to updated_exporter.cpython-36.pyc\n",
            "Sorry: IndentationError: unexpected indent (updated_exporter.py, line 320)\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "object_detection.core.__pycache__.preprocessor.cpython-36: module MAY be using inspect.stack\n",
            "object_detection.utils.__pycache__.autoaugment_utils.cpython-36: module MAY be using inspect.stack\n",
            "creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing object_detection-0.1-py3.6.egg\n",
            "removing '/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n",
            "Extracting object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Sorry: IndentationError: unexpected indent (updated_exporter.py, line 320)\n",
            "object-detection 0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n",
            "Processing dependencies for object-detection==0.1\n",
            "Searching for Cython==0.29.14\n",
            "Best match: Cython 0.29.14\n",
            "Adding Cython 0.29.14 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for matplotlib==3.1.2\n",
            "Best match: matplotlib 3.1.2\n",
            "Adding matplotlib 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==6.2.2\n",
            "Best match: Pillow 6.2.2\n",
            "Adding Pillow 6.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyparsing==2.4.6\n",
            "Best match: pyparsing 2.4.6\n",
            "Adding pyparsing 2.4.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.6.1\n",
            "Best match: python-dateutil 2.6.1\n",
            "Adding python-dateutil 2.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.17.5\n",
            "Best match: numpy 1.17.5\n",
            "Adding numpy 1.17.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for kiwisolver==1.1.0\n",
            "Best match: kiwisolver 1.1.0\n",
            "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==42.0.2\n",
            "Best match: setuptools 42.0.2\n",
            "Adding setuptools 42.0.2 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for object-detection==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__pOM4iJXM9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile into py files for the slim folder \n",
        "# otherwise the updated_exporter will not work \n",
        "# because the nets module can't be found \n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research/slim\n",
        "!python setup.py build\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LozDRaXF0hp",
        "colab_type": "code",
        "outputId": "d432fc20-85db-44d5-e668-06911897940f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        }
      },
      "source": [
        "# path  = ':/content/drive/My Drive/{0}/models/research/:/content/drive/My Drive/{0}/models/research/slim'.format(maindirectory)\n",
        "os.environ['PYTHONPATH'] += ':./:./slim/'\n",
        "\n",
        "\n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research\n",
        "# testing the model builder\n",
        "!python3 object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.234s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQMASjFxAktF",
        "colab_type": "text"
      },
      "source": [
        "# convert export_inference_graph back to original\n",
        "\n",
        "* only change is from object_detection import exporter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Ji11UlArPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38b75b1b-6432-408a-f137-a3c9fb69d9e4"
      },
      "source": [
        "%cd /content/drive/'My Drive'/$maindirectory/models/research/object_detection"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmDnN0WkAuaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ca6ab15-42ad-4772-a297-c6b5169e9f2a"
      },
      "source": [
        "%%writefile export_inference_graph.py\n",
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "r\"\"\"Tool to export an object detection model for inference.\n",
        "\n",
        "Prepares an object detection tensorflow graph for inference using model\n",
        "configuration and a trained checkpoint. Outputs inference\n",
        "graph, associated checkpoint files, a frozen inference graph and a\n",
        "SavedModel (https://tensorflow.github.io/serving/serving_basic.html).\n",
        "\n",
        "The inference graph contains one of three input nodes depending on the user\n",
        "specified option.\n",
        "  * `image_tensor`: Accepts a uint8 4-D tensor of shape [None, None, None, 3]\n",
        "  * `encoded_image_string_tensor`: Accepts a 1-D string tensor of shape [None]\n",
        "    containing encoded PNG or JPEG images. Image resolutions are expected to be\n",
        "    the same if more than 1 image is provided.\n",
        "  * `tf_example`: Accepts a 1-D string tensor of shape [None] containing\n",
        "    serialized TFExample protos. Image resolutions are expected to be the same\n",
        "    if more than 1 image is provided.\n",
        "\n",
        "and the following output nodes returned by the model.postprocess(..):\n",
        "  * `num_detections`: Outputs float32 tensors of the form [batch]\n",
        "      that specifies the number of valid boxes per image in the batch.\n",
        "  * `detection_boxes`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes, 4] containing detected boxes.\n",
        "  * `detection_scores`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes] containing class scores for the detections.\n",
        "  * `detection_classes`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes] containing classes for the detections.\n",
        "  * `raw_detection_boxes`: Outputs float32 tensors of the form\n",
        "      [batch, raw_num_boxes, 4] containing detection boxes without\n",
        "      post-processing.\n",
        "  * `raw_detection_scores`: Outputs float32 tensors of the form\n",
        "      [batch, raw_num_boxes, num_classes_with_background] containing class score\n",
        "      logits for raw detection boxes.\n",
        "  * `detection_masks`: (Optional) Outputs float32 tensors of the form\n",
        "      [batch, num_boxes, mask_height, mask_width] containing predicted instance\n",
        "      masks for each box if its present in the dictionary of postprocessed\n",
        "      tensors returned by the model.\n",
        "  * detection_multiclass_scores: (Optional) Outputs float32 tensor of shape\n",
        "      [batch, num_boxes, num_classes_with_background] for containing class\n",
        "      score distribution for detected boxes including background if any.\n",
        "  * detection_features: (Optional) float32 tensor of shape\n",
        "      [batch, num_boxes, roi_height, roi_width, depth]\n",
        "  containing classifier features\n",
        "\n",
        "Notes:\n",
        " * This tool uses `use_moving_averages` from eval_config to decide which\n",
        "   weights to freeze.\n",
        "\n",
        "Example Usage:\n",
        "--------------\n",
        "python export_inference_graph \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path path/to/ssd_inception_v2.config \\\n",
        "    --trained_checkpoint_prefix path/to/model.ckpt \\\n",
        "    --output_directory path/to/exported_model_directory\n",
        "\n",
        "The expected output would be in the directory\n",
        "path/to/exported_model_directory (which is created if it does not exist)\n",
        "with contents:\n",
        " - inference_graph.pbtxt\n",
        " - model.ckpt.data-00000-of-00001\n",
        " - model.ckpt.info\n",
        " - model.ckpt.meta\n",
        " - frozen_inference_graph.pb\n",
        " + saved_model (a directory)\n",
        "\n",
        "Config overrides (see the `config_override` flag) are text protobufs\n",
        "(also of type pipeline_pb2.TrainEvalPipelineConfig) which are used to override\n",
        "certain fields in the provided pipeline_config_path.  These are useful for\n",
        "making small changes to the inference graph that differ from the training or\n",
        "eval config.\n",
        "\n",
        "Example Usage (in which we change the second stage post-processing score\n",
        "threshold to be 0.5):\n",
        "\n",
        "python export_inference_graph \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path path/to/ssd_inception_v2.config \\\n",
        "    --trained_checkpoint_prefix path/to/model.ckpt \\\n",
        "    --output_directory path/to/exported_model_directory \\\n",
        "    --config_override \" \\\n",
        "            model{ \\\n",
        "              faster_rcnn { \\\n",
        "                second_stage_post_processing { \\\n",
        "                  batch_non_max_suppression { \\\n",
        "                    score_threshold: 0.5 \\\n",
        "                  } \\\n",
        "                } \\\n",
        "              } \\\n",
        "            }\"\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection import exporter\n",
        "from object_detection.protos import pipeline_pb2\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "flags = tf.app.flags\n",
        "\n",
        "flags.DEFINE_string('input_type', 'image_tensor', 'Type of input node. Can be '\n",
        "                    'one of [`image_tensor`, `encoded_image_string_tensor`, '\n",
        "                    '`tf_example`]')\n",
        "flags.DEFINE_string('input_shape', None,\n",
        "                    'If input_type is `image_tensor`, this can explicitly set '\n",
        "                    'the shape of this input tensor to a fixed size. The '\n",
        "                    'dimensions are to be provided as a comma-separated list '\n",
        "                    'of integers. A value of -1 can be used for unknown '\n",
        "                    'dimensions. If not specified, for an `image_tensor, the '\n",
        "                    'default shape will be partially specified as '\n",
        "                    '`[None, None, None, 3]`.')\n",
        "flags.DEFINE_string('pipeline_config_path', None,\n",
        "                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
        "                    'file.')\n",
        "flags.DEFINE_string('trained_checkpoint_prefix', None,\n",
        "                    'Path to trained checkpoint, typically of the form '\n",
        "                    'path/to/model.ckpt')\n",
        "flags.DEFINE_string('output_directory', None, 'Path to write outputs.')\n",
        "flags.DEFINE_string('config_override', '',\n",
        "                    'pipeline_pb2.TrainEvalPipelineConfig '\n",
        "                    'text proto to override pipeline_config_path.')\n",
        "flags.DEFINE_boolean('write_inference_graph', False,\n",
        "                     'If true, writes inference graph to disk.')\n",
        "tf.app.flags.mark_flag_as_required('pipeline_config_path')\n",
        "tf.app.flags.mark_flag_as_required('trained_checkpoint_prefix')\n",
        "tf.app.flags.mark_flag_as_required('output_directory')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def main(_):\n",
        "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "  with tf.gfile.GFile(FLAGS.pipeline_config_path, 'r') as f:\n",
        "    text_format.Merge(f.read(), pipeline_config)\n",
        "  text_format.Merge(FLAGS.config_override, pipeline_config)\n",
        "  if FLAGS.input_shape:\n",
        "    input_shape = [\n",
        "        int(dim) if dim != '-1' else None\n",
        "        for dim in FLAGS.input_shape.split(',')\n",
        "    ]\n",
        "  else:\n",
        "    input_shape = None\n",
        "  exporter.export_inference_graph(\n",
        "      FLAGS.input_type, pipeline_config, FLAGS.trained_checkpoint_prefix,\n",
        "      FLAGS.output_directory, input_shape=input_shape,\n",
        "      write_inference_graph=FLAGS.write_inference_graph)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting export_inference_graph.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo0x-QCsJWTy",
        "colab_type": "text"
      },
      "source": [
        "# create an updated exporter.py \n",
        "\n",
        "* Update write_saved_model\n",
        "\n",
        "<pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">write_saved_model</span>(<span class=\"pl-smi\">saved_model_path</span>,\n",
        "                      <span class=\"pl-smi\">trained_checkpoint_prefix</span>,\n",
        "                      <span class=\"pl-smi\">inputs</span>,\n",
        "                      <span class=\"pl-smi\">outputs</span>):\n",
        "\n",
        "  saver <span class=\"pl-k\">=</span> tf.train.Saver()\n",
        "  <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n",
        "    saver.restore(sess, trained_checkpoint_prefix)\n",
        "\n",
        "    builder <span class=\"pl-k\">=</span> tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n",
        "\n",
        "    tensor_info_inputs <span class=\"pl-k\">=</span> {\n",
        "        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>inputs<span class=\"pl-pds\">'</span></span>: tf.saved_model.utils.build_tensor_info(inputs)}\n",
        "    tensor_info_outputs <span class=\"pl-k\">=</span> {}\n",
        "    <span class=\"pl-k\">for</span> k, v <span class=\"pl-k\">in</span> outputs.items():\n",
        "      tensor_info_outputs[k] <span class=\"pl-k\">=</span> tf.saved_model.utils.build_tensor_info(v)\n",
        "\n",
        "    detection_signature <span class=\"pl-k\">=</span> (\n",
        "        tf.saved_model.signature_def_utils.build_signature_def(\n",
        "            <span class=\"pl-v\">inputs</span><span class=\"pl-k\">=</span>tensor_info_inputs,\n",
        "            <span class=\"pl-v\">outputs</span><span class=\"pl-k\">=</span>tensor_info_outputs,\n",
        "            <span class=\"pl-v\">method_name</span><span class=\"pl-k\">=</span>tf.saved_model.signature_constants.<span class=\"pl-c1\">PREDICT_METHOD_NAME</span>\n",
        "        ))\n",
        "\n",
        "    builder.add_meta_graph_and_variables(\n",
        "        sess,\n",
        "        [tf.saved_model.tag_constants.<span class=\"pl-c1\">SERVING</span>],\n",
        "        <span class=\"pl-v\">signature_def_map</span><span class=\"pl-k\">=</span>{\n",
        "            tf.saved_model.signature_constants\n",
        "            .<span class=\"pl-c1\">DEFAULT_SERVING_SIGNATURE_DEF_KEY</span>:\n",
        "                detection_signature,\n",
        "        },\n",
        "    )\n",
        "    builder.save()</pre>\n",
        "\n",
        "\n",
        "* Update _export_inference_graph in exporter.py </br>\n",
        "Then, within the _export_inference_graph function, update the final line to pass the checkpoint prefix like\n",
        "\n",
        "---\n",
        "\n",
        "`write_saved_model(saved_model_path, frozen_graph_def,\n",
        "                    placeholder_tensor, outputs)`\n",
        "\n",
        "to \n",
        "\n",
        "`write_saved_model(saved_model_path, trained_checkpoint_prefix,\n",
        "                    placeholder_tensor, outputs)`\n",
        "\n",
        "---\n",
        "\n",
        "add the following inputs:\n",
        "* from tensorflow.python.client import session\n",
        "* from tensorflow.python.saved_model import signature_constants  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NX_DasglZ8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82f586b0-d727-4db2-c505-facf1cab88df"
      },
      "source": [
        "%cd /content/drive/'My Drive'/$maindirectory/models/research/object_detection"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAVzuYfhnaCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3768133-fe1a-4880-d131-2cc89b6c483f"
      },
      "source": [
        "!cat exporter.py"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
            "#\n",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "# you may not use this file except in compliance with the License.\n",
            "# You may obtain a copy of the License at\n",
            "#\n",
            "#     http://www.apache.org/licenses/LICENSE-2.0\n",
            "#\n",
            "# Unless required by applicable law or agreed to in writing, software\n",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "# See the License for the specific language governing permissions and\n",
            "# limitations under the License.\n",
            "# ==============================================================================\n",
            "\n",
            "\"\"\"Functions to export object detection inference graph.\"\"\"\n",
            "import os\n",
            "import tempfile\n",
            "import tensorflow as tf\n",
            "from tensorflow.contrib.quantize.python import graph_matcher\n",
            "from tensorflow.core.protobuf import saver_pb2\n",
            "from tensorflow.python.tools import freeze_graph  # pylint: disable=g-direct-tensorflow-import\n",
            "from object_detection.builders import graph_rewriter_builder\n",
            "from object_detection.builders import model_builder\n",
            "from object_detection.core import standard_fields as fields\n",
            "from object_detection.data_decoders import tf_example_decoder\n",
            "from object_detection.utils import config_util\n",
            "from object_detection.utils import shape_utils\n",
            "\n",
            "slim = tf.contrib.slim\n",
            "\n",
            "freeze_graph_with_def_protos = freeze_graph.freeze_graph_with_def_protos\n",
            "\n",
            "\n",
            "def rewrite_nn_resize_op(is_quantized=False):\n",
            "  \"\"\"Replaces a custom nearest-neighbor resize op with the Tensorflow version.\n",
            "\n",
            "  Some graphs use this custom version for TPU-compatibility.\n",
            "\n",
            "  Args:\n",
            "    is_quantized: True if the default graph is quantized.\n",
            "  \"\"\"\n",
            "  def remove_nn():\n",
            "    \"\"\"Remove nearest neighbor upsampling structure and replace with TF op.\"\"\"\n",
            "    input_pattern = graph_matcher.OpTypePattern(\n",
            "        'FakeQuantWithMinMaxVars' if is_quantized else '*')\n",
            "    stack_1_pattern = graph_matcher.OpTypePattern(\n",
            "        'Pack', inputs=[input_pattern, input_pattern], ordered_inputs=False)\n",
            "    stack_2_pattern = graph_matcher.OpTypePattern(\n",
            "        'Pack', inputs=[stack_1_pattern, stack_1_pattern], ordered_inputs=False)\n",
            "    reshape_pattern = graph_matcher.OpTypePattern(\n",
            "        'Reshape', inputs=[stack_2_pattern, 'Const'], ordered_inputs=False)\n",
            "    consumer_pattern = graph_matcher.OpTypePattern(\n",
            "        'Add|AddV2|Max|Mul', inputs=[reshape_pattern, '*'],\n",
            "        ordered_inputs=False)\n",
            "\n",
            "    match_counter = 0\n",
            "    matcher = graph_matcher.GraphMatcher(consumer_pattern)\n",
            "    for match in matcher.match_graph(tf.get_default_graph()):\n",
            "      match_counter += 1\n",
            "      projection_op = match.get_op(input_pattern)\n",
            "      reshape_op = match.get_op(reshape_pattern)\n",
            "      consumer_op = match.get_op(consumer_pattern)\n",
            "      nn_resize = tf.image.resize_nearest_neighbor(\n",
            "          projection_op.outputs[0],\n",
            "          reshape_op.outputs[0].shape.dims[1:3],\n",
            "          align_corners=False,\n",
            "          name=os.path.split(reshape_op.name)[0] + '/resize_nearest_neighbor')\n",
            "\n",
            "      for index, op_input in enumerate(consumer_op.inputs):\n",
            "        if op_input == reshape_op.outputs[0]:\n",
            "          consumer_op._update_input(index, nn_resize)  # pylint: disable=protected-access\n",
            "          break\n",
            "\n",
            "    tf.logging.info('Found and fixed {} matches'.format(match_counter))\n",
            "    return match_counter\n",
            "\n",
            "  # Applying twice because both inputs to Add could be NN pattern\n",
            "  total_removals = 0\n",
            "  while remove_nn():\n",
            "    total_removals += 1\n",
            "    # This number is chosen based on the nas-fpn architecture.\n",
            "    if total_removals > 4:\n",
            "      raise ValueError('Graph removal encountered a infinite loop.')\n",
            "\n",
            "\n",
            "def replace_variable_values_with_moving_averages(graph,\n",
            "                                                 current_checkpoint_file,\n",
            "                                                 new_checkpoint_file,\n",
            "                                                 no_ema_collection=None):\n",
            "  \"\"\"Replaces variable values in the checkpoint with their moving averages.\n",
            "\n",
            "  If the current checkpoint has shadow variables maintaining moving averages of\n",
            "  the variables defined in the graph, this function generates a new checkpoint\n",
            "  where the variables contain the values of their moving averages.\n",
            "\n",
            "  Args:\n",
            "    graph: a tf.Graph object.\n",
            "    current_checkpoint_file: a checkpoint containing both original variables and\n",
            "      their moving averages.\n",
            "    new_checkpoint_file: file path to write a new checkpoint.\n",
            "    no_ema_collection: A list of namescope substrings to match the variables\n",
            "      to eliminate EMA.\n",
            "  \"\"\"\n",
            "  with graph.as_default():\n",
            "    variable_averages = tf.train.ExponentialMovingAverage(0.0)\n",
            "    ema_variables_to_restore = variable_averages.variables_to_restore()\n",
            "    ema_variables_to_restore = config_util.remove_unecessary_ema(\n",
            "        ema_variables_to_restore, no_ema_collection)\n",
            "    with tf.Session() as sess:\n",
            "      read_saver = tf.train.Saver(ema_variables_to_restore)\n",
            "      read_saver.restore(sess, current_checkpoint_file)\n",
            "      write_saver = tf.train.Saver()\n",
            "      write_saver.save(sess, new_checkpoint_file)\n",
            "\n",
            "\n",
            "def _image_tensor_input_placeholder(input_shape=None):\n",
            "  \"\"\"Returns input placeholder and a 4-D uint8 image tensor.\"\"\"\n",
            "  if input_shape is None:\n",
            "    input_shape = (None, None, None, 3)\n",
            "  input_tensor = tf.placeholder(\n",
            "      dtype=tf.uint8, shape=input_shape, name='image_tensor')\n",
            "  return input_tensor, input_tensor\n",
            "\n",
            "\n",
            "def _tf_example_input_placeholder(input_shape=None):\n",
            "  \"\"\"Returns input that accepts a batch of strings with tf examples.\n",
            "\n",
            "  Args:\n",
            "    input_shape: the shape to resize the output decoded images to (optional).\n",
            "\n",
            "  Returns:\n",
            "    a tuple of input placeholder and the output decoded images.\n",
            "  \"\"\"\n",
            "  batch_tf_example_placeholder = tf.placeholder(\n",
            "      tf.string, shape=[None], name='tf_example')\n",
            "  def decode(tf_example_string_tensor):\n",
            "    tensor_dict = tf_example_decoder.TfExampleDecoder().decode(\n",
            "        tf_example_string_tensor)\n",
            "    image_tensor = tensor_dict[fields.InputDataFields.image]\n",
            "    if input_shape is not None:\n",
            "      image_tensor = tf.image.resize(image_tensor, input_shape[1:3])\n",
            "    return image_tensor\n",
            "  return (batch_tf_example_placeholder,\n",
            "          shape_utils.static_or_dynamic_map_fn(\n",
            "              decode,\n",
            "              elems=batch_tf_example_placeholder,\n",
            "              dtype=tf.uint8,\n",
            "              parallel_iterations=32,\n",
            "              back_prop=False))\n",
            "\n",
            "\n",
            "def _encoded_image_string_tensor_input_placeholder(input_shape=None):\n",
            "  \"\"\"Returns input that accepts a batch of PNG or JPEG strings.\n",
            "\n",
            "  Args:\n",
            "    input_shape: the shape to resize the output decoded images to (optional).\n",
            "\n",
            "  Returns:\n",
            "    a tuple of input placeholder and the output decoded images.\n",
            "  \"\"\"\n",
            "  batch_image_str_placeholder = tf.placeholder(\n",
            "      dtype=tf.string,\n",
            "      shape=[None],\n",
            "      name='encoded_image_string_tensor')\n",
            "  def decode(encoded_image_string_tensor):\n",
            "    image_tensor = tf.image.decode_image(encoded_image_string_tensor,\n",
            "                                         channels=3)\n",
            "    image_tensor.set_shape((None, None, 3))\n",
            "    if input_shape is not None:\n",
            "      image_tensor = tf.image.resize(image_tensor, input_shape[1:3])\n",
            "    return image_tensor\n",
            "  return (batch_image_str_placeholder,\n",
            "          tf.map_fn(\n",
            "              decode,\n",
            "              elems=batch_image_str_placeholder,\n",
            "              dtype=tf.uint8,\n",
            "              parallel_iterations=32,\n",
            "              back_prop=False))\n",
            "\n",
            "\n",
            "input_placeholder_fn_map = {\n",
            "    'image_tensor': _image_tensor_input_placeholder,\n",
            "    'encoded_image_string_tensor':\n",
            "    _encoded_image_string_tensor_input_placeholder,\n",
            "    'tf_example': _tf_example_input_placeholder,\n",
            "}\n",
            "\n",
            "\n",
            "def add_output_tensor_nodes(postprocessed_tensors,\n",
            "                            output_collection_name='inference_op'):\n",
            "  \"\"\"Adds output nodes for detection boxes and scores.\n",
            "\n",
            "  Adds the following nodes for output tensors -\n",
            "    * num_detections: float32 tensor of shape [batch_size].\n",
            "    * detection_boxes: float32 tensor of shape [batch_size, num_boxes, 4]\n",
            "      containing detected boxes.\n",
            "    * detection_scores: float32 tensor of shape [batch_size, num_boxes]\n",
            "      containing scores for the detected boxes.\n",
            "    * detection_multiclass_scores: (Optional) float32 tensor of shape\n",
            "      [batch_size, num_boxes, num_classes_with_background] for containing class\n",
            "      score distribution for detected boxes including background if any.\n",
            "    * detection_features: (Optional) float32 tensor of shape\n",
            "      [batch, num_boxes, roi_height, roi_width, depth]\n",
            "      containing classifier features\n",
            "      for each detected box\n",
            "    * detection_classes: float32 tensor of shape [batch_size, num_boxes]\n",
            "      containing class predictions for the detected boxes.\n",
            "    * detection_keypoints: (Optional) float32 tensor of shape\n",
            "      [batch_size, num_boxes, num_keypoints, 2] containing keypoints for each\n",
            "      detection box.\n",
            "    * detection_masks: (Optional) float32 tensor of shape\n",
            "      [batch_size, num_boxes, mask_height, mask_width] containing masks for each\n",
            "      detection box.\n",
            "\n",
            "  Args:\n",
            "    postprocessed_tensors: a dictionary containing the following fields\n",
            "      'detection_boxes': [batch, max_detections, 4]\n",
            "      'detection_scores': [batch, max_detections]\n",
            "      'detection_multiclass_scores': [batch, max_detections,\n",
            "        num_classes_with_background]\n",
            "      'detection_features': [batch, num_boxes, roi_height, roi_width, depth]\n",
            "      'detection_classes': [batch, max_detections]\n",
            "      'detection_masks': [batch, max_detections, mask_height, mask_width]\n",
            "        (optional).\n",
            "      'detection_keypoints': [batch, max_detections, num_keypoints, 2]\n",
            "        (optional).\n",
            "      'num_detections': [batch]\n",
            "    output_collection_name: Name of collection to add output tensors to.\n",
            "\n",
            "  Returns:\n",
            "    A tensor dict containing the added output tensor nodes.\n",
            "  \"\"\"\n",
            "  detection_fields = fields.DetectionResultFields\n",
            "  label_id_offset = 1\n",
            "  boxes = postprocessed_tensors.get(detection_fields.detection_boxes)\n",
            "  scores = postprocessed_tensors.get(detection_fields.detection_scores)\n",
            "  multiclass_scores = postprocessed_tensors.get(\n",
            "      detection_fields.detection_multiclass_scores)\n",
            "  box_classifier_features = postprocessed_tensors.get(\n",
            "      detection_fields.detection_features)\n",
            "  raw_boxes = postprocessed_tensors.get(detection_fields.raw_detection_boxes)\n",
            "  raw_scores = postprocessed_tensors.get(detection_fields.raw_detection_scores)\n",
            "  classes = postprocessed_tensors.get(\n",
            "      detection_fields.detection_classes) + label_id_offset\n",
            "  keypoints = postprocessed_tensors.get(detection_fields.detection_keypoints)\n",
            "  masks = postprocessed_tensors.get(detection_fields.detection_masks)\n",
            "  num_detections = postprocessed_tensors.get(detection_fields.num_detections)\n",
            "  outputs = {}\n",
            "  outputs[detection_fields.detection_boxes] = tf.identity(\n",
            "      boxes, name=detection_fields.detection_boxes)\n",
            "  outputs[detection_fields.detection_scores] = tf.identity(\n",
            "      scores, name=detection_fields.detection_scores)\n",
            "  if multiclass_scores is not None:\n",
            "    outputs[detection_fields.detection_multiclass_scores] = tf.identity(\n",
            "        multiclass_scores, name=detection_fields.detection_multiclass_scores)\n",
            "  if box_classifier_features is not None:\n",
            "    outputs[detection_fields.detection_features] = tf.identity(\n",
            "        box_classifier_features,\n",
            "        name=detection_fields.detection_features)\n",
            "  outputs[detection_fields.detection_classes] = tf.identity(\n",
            "      classes, name=detection_fields.detection_classes)\n",
            "  outputs[detection_fields.num_detections] = tf.identity(\n",
            "      num_detections, name=detection_fields.num_detections)\n",
            "  if raw_boxes is not None:\n",
            "    outputs[detection_fields.raw_detection_boxes] = tf.identity(\n",
            "        raw_boxes, name=detection_fields.raw_detection_boxes)\n",
            "  if raw_scores is not None:\n",
            "    outputs[detection_fields.raw_detection_scores] = tf.identity(\n",
            "        raw_scores, name=detection_fields.raw_detection_scores)\n",
            "  if keypoints is not None:\n",
            "    outputs[detection_fields.detection_keypoints] = tf.identity(\n",
            "        keypoints, name=detection_fields.detection_keypoints)\n",
            "  if masks is not None:\n",
            "    outputs[detection_fields.detection_masks] = tf.identity(\n",
            "        masks, name=detection_fields.detection_masks)\n",
            "  for output_key in outputs:\n",
            "    tf.add_to_collection(output_collection_name, outputs[output_key])\n",
            "\n",
            "  return outputs\n",
            "\n",
            "\n",
            "def write_saved_model(saved_model_path,\n",
            "                      frozen_graph_def,\n",
            "                      inputs,\n",
            "                      outputs):\n",
            "  \"\"\"Writes SavedModel to disk.\n",
            "\n",
            "  If checkpoint_path is not None bakes the weights into the graph thereby\n",
            "  eliminating the need of checkpoint files during inference. If the model\n",
            "  was trained with moving averages, setting use_moving_averages to true\n",
            "  restores the moving averages, otherwise the original set of variables\n",
            "  is restored.\n",
            "\n",
            "  Args:\n",
            "    saved_model_path: Path to write SavedModel.\n",
            "    frozen_graph_def: tf.GraphDef holding frozen graph.\n",
            "    inputs: The input placeholder tensor.\n",
            "    outputs: A tensor dictionary containing the outputs of a DetectionModel.\n",
            "  \"\"\"\n",
            "  with tf.Graph().as_default():\n",
            "    with tf.Session() as sess:\n",
            "\n",
            "      tf.import_graph_def(frozen_graph_def, name='')\n",
            "\n",
            "      builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n",
            "\n",
            "      tensor_info_inputs = {\n",
            "          'inputs': tf.saved_model.utils.build_tensor_info(inputs)}\n",
            "      tensor_info_outputs = {}\n",
            "      for k, v in outputs.items():\n",
            "        tensor_info_outputs[k] = tf.saved_model.utils.build_tensor_info(v)\n",
            "\n",
            "      detection_signature = (\n",
            "          tf.saved_model.signature_def_utils.build_signature_def(\n",
            "              inputs=tensor_info_inputs,\n",
            "              outputs=tensor_info_outputs,\n",
            "              method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
            "          ))\n",
            "\n",
            "      builder.add_meta_graph_and_variables(\n",
            "          sess,\n",
            "          [tf.saved_model.tag_constants.SERVING],\n",
            "          signature_def_map={\n",
            "              tf.saved_model.signature_constants\n",
            "              .DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
            "                  detection_signature,\n",
            "          },\n",
            "      )\n",
            "      builder.save()\n",
            "\n",
            "\n",
            "def write_graph_and_checkpoint(inference_graph_def,\n",
            "                               model_path,\n",
            "                               input_saver_def,\n",
            "                               trained_checkpoint_prefix):\n",
            "  \"\"\"Writes the graph and the checkpoint into disk.\"\"\"\n",
            "  for node in inference_graph_def.node:\n",
            "    node.device = ''\n",
            "  with tf.Graph().as_default():\n",
            "    tf.import_graph_def(inference_graph_def, name='')\n",
            "    with tf.Session() as sess:\n",
            "      saver = tf.train.Saver(\n",
            "          saver_def=input_saver_def, save_relative_paths=True)\n",
            "      saver.restore(sess, trained_checkpoint_prefix)\n",
            "      saver.save(sess, model_path)\n",
            "\n",
            "\n",
            "def _get_outputs_from_inputs(input_tensors, detection_model,\n",
            "                             output_collection_name):\n",
            "  inputs = tf.cast(input_tensors, dtype=tf.float32)\n",
            "  preprocessed_inputs, true_image_shapes = detection_model.preprocess(inputs)\n",
            "  output_tensors = detection_model.predict(\n",
            "      preprocessed_inputs, true_image_shapes)\n",
            "  postprocessed_tensors = detection_model.postprocess(\n",
            "      output_tensors, true_image_shapes)\n",
            "  return add_output_tensor_nodes(postprocessed_tensors,\n",
            "                                 output_collection_name)\n",
            "\n",
            "\n",
            "def build_detection_graph(input_type, detection_model, input_shape,\n",
            "                          output_collection_name, graph_hook_fn):\n",
            "  \"\"\"Build the detection graph.\"\"\"\n",
            "  if input_type not in input_placeholder_fn_map:\n",
            "    raise ValueError('Unknown input type: {}'.format(input_type))\n",
            "  placeholder_args = {}\n",
            "  if input_shape is not None:\n",
            "    if (input_type != 'image_tensor' and\n",
            "        input_type != 'encoded_image_string_tensor' and\n",
            "        input_type != 'tf_example'):\n",
            "      raise ValueError('Can only specify input shape for `image_tensor`, '\n",
            "                       '`encoded_image_string_tensor`, or `tf_example` '\n",
            "                       'inputs.')\n",
            "    placeholder_args['input_shape'] = input_shape\n",
            "  placeholder_tensor, input_tensors = input_placeholder_fn_map[input_type](\n",
            "      **placeholder_args)\n",
            "  outputs = _get_outputs_from_inputs(\n",
            "      input_tensors=input_tensors,\n",
            "      detection_model=detection_model,\n",
            "      output_collection_name=output_collection_name)\n",
            "\n",
            "  # Add global step to the graph.\n",
            "  slim.get_or_create_global_step()\n",
            "\n",
            "  if graph_hook_fn: graph_hook_fn()\n",
            "\n",
            "  return outputs, placeholder_tensor\n",
            "\n",
            "\n",
            "def _export_inference_graph(input_type,\n",
            "                            detection_model,\n",
            "                            use_moving_averages,\n",
            "                            trained_checkpoint_prefix,\n",
            "                            output_directory,\n",
            "                            additional_output_tensor_names=None,\n",
            "                            input_shape=None,\n",
            "                            output_collection_name='inference_op',\n",
            "                            graph_hook_fn=None,\n",
            "                            write_inference_graph=False,\n",
            "                            temp_checkpoint_prefix=''):\n",
            "  \"\"\"Export helper.\"\"\"\n",
            "  tf.gfile.MakeDirs(output_directory)\n",
            "  frozen_graph_path = os.path.join(output_directory,\n",
            "                                   'frozen_inference_graph.pb')\n",
            "  saved_model_path = os.path.join(output_directory, 'saved_model')\n",
            "  model_path = os.path.join(output_directory, 'model.ckpt')\n",
            "\n",
            "  outputs, placeholder_tensor = build_detection_graph(\n",
            "      input_type=input_type,\n",
            "      detection_model=detection_model,\n",
            "      input_shape=input_shape,\n",
            "      output_collection_name=output_collection_name,\n",
            "      graph_hook_fn=graph_hook_fn)\n",
            "\n",
            "  profile_inference_graph(tf.get_default_graph())\n",
            "  saver_kwargs = {}\n",
            "  if use_moving_averages:\n",
            "    if not temp_checkpoint_prefix:\n",
            "      # This check is to be compatible with both version of SaverDef.\n",
            "      if os.path.isfile(trained_checkpoint_prefix):\n",
            "        saver_kwargs['write_version'] = saver_pb2.SaverDef.V1\n",
            "        temp_checkpoint_prefix = tempfile.NamedTemporaryFile().name\n",
            "      else:\n",
            "        temp_checkpoint_prefix = tempfile.mkdtemp()\n",
            "    replace_variable_values_with_moving_averages(\n",
            "        tf.get_default_graph(), trained_checkpoint_prefix,\n",
            "        temp_checkpoint_prefix)\n",
            "    checkpoint_to_use = temp_checkpoint_prefix\n",
            "  else:\n",
            "    checkpoint_to_use = trained_checkpoint_prefix\n",
            "\n",
            "  saver = tf.train.Saver(**saver_kwargs)\n",
            "  input_saver_def = saver.as_saver_def()\n",
            "\n",
            "  write_graph_and_checkpoint(\n",
            "      inference_graph_def=tf.get_default_graph().as_graph_def(),\n",
            "      model_path=model_path,\n",
            "      input_saver_def=input_saver_def,\n",
            "      trained_checkpoint_prefix=checkpoint_to_use)\n",
            "  if write_inference_graph:\n",
            "    inference_graph_def = tf.get_default_graph().as_graph_def()\n",
            "    inference_graph_path = os.path.join(output_directory,\n",
            "                                        'inference_graph.pbtxt')\n",
            "    for node in inference_graph_def.node:\n",
            "      node.device = ''\n",
            "    with tf.gfile.GFile(inference_graph_path, 'wb') as f:\n",
            "      f.write(str(inference_graph_def))\n",
            "\n",
            "  if additional_output_tensor_names is not None:\n",
            "    output_node_names = ','.join(outputs.keys()+additional_output_tensor_names)\n",
            "  else:\n",
            "    output_node_names = ','.join(outputs.keys())\n",
            "\n",
            "  frozen_graph_def = freeze_graph.freeze_graph_with_def_protos(\n",
            "      input_graph_def=tf.get_default_graph().as_graph_def(),\n",
            "      input_saver_def=input_saver_def,\n",
            "      input_checkpoint=checkpoint_to_use,\n",
            "      output_node_names=output_node_names,\n",
            "      restore_op_name='save/restore_all',\n",
            "      filename_tensor_name='save/Const:0',\n",
            "      output_graph=frozen_graph_path,\n",
            "      clear_devices=True,\n",
            "      initializer_nodes='')\n",
            "\n",
            "  write_saved_model(saved_model_path, frozen_graph_def,\n",
            "                    placeholder_tensor, outputs)\n",
            "\n",
            "\n",
            "def export_inference_graph(input_type,\n",
            "                           pipeline_config,\n",
            "                           trained_checkpoint_prefix,\n",
            "                           output_directory,\n",
            "                           input_shape=None,\n",
            "                           output_collection_name='inference_op',\n",
            "                           additional_output_tensor_names=None,\n",
            "                           write_inference_graph=False):\n",
            "  \"\"\"Exports inference graph for the model specified in the pipeline config.\n",
            "\n",
            "  Args:\n",
            "    input_type: Type of input for the graph. Can be one of ['image_tensor',\n",
            "      'encoded_image_string_tensor', 'tf_example'].\n",
            "    pipeline_config: pipeline_pb2.TrainAndEvalPipelineConfig proto.\n",
            "    trained_checkpoint_prefix: Path to the trained checkpoint file.\n",
            "    output_directory: Path to write outputs.\n",
            "    input_shape: Sets a fixed shape for an `image_tensor` input. If not\n",
            "      specified, will default to [None, None, None, 3].\n",
            "    output_collection_name: Name of collection to add output tensors to.\n",
            "      If None, does not add output tensors to a collection.\n",
            "    additional_output_tensor_names: list of additional output\n",
            "      tensors to include in the frozen graph.\n",
            "    write_inference_graph: If true, writes inference graph to disk.\n",
            "  \"\"\"\n",
            "  detection_model = model_builder.build(pipeline_config.model,\n",
            "                                        is_training=False)\n",
            "  graph_rewriter_fn = None\n",
            "  if pipeline_config.HasField('graph_rewriter'):\n",
            "    graph_rewriter_config = pipeline_config.graph_rewriter\n",
            "    graph_rewriter_fn = graph_rewriter_builder.build(graph_rewriter_config,\n",
            "                                                     is_training=False)\n",
            "  _export_inference_graph(\n",
            "      input_type,\n",
            "      detection_model,\n",
            "      pipeline_config.eval_config.use_moving_averages,\n",
            "      trained_checkpoint_prefix,\n",
            "      output_directory,\n",
            "      additional_output_tensor_names,\n",
            "      input_shape,\n",
            "      output_collection_name,\n",
            "      graph_hook_fn=graph_rewriter_fn,\n",
            "      write_inference_graph=write_inference_graph)\n",
            "  pipeline_config.eval_config.use_moving_averages = False\n",
            "  config_util.save_pipeline_config(pipeline_config, output_directory)\n",
            "\n",
            "\n",
            "def profile_inference_graph(graph):\n",
            "  \"\"\"Profiles the inference graph.\n",
            "\n",
            "  Prints model parameters and computation FLOPs given an inference graph.\n",
            "  BatchNorms are excluded from the parameter count due to the fact that\n",
            "  BatchNorms are usually folded. BatchNorm, Initializer, Regularizer\n",
            "  and BiasAdd are not considered in FLOP count.\n",
            "\n",
            "  Args:\n",
            "    graph: the inference graph.\n",
            "  \"\"\"\n",
            "  tfprof_vars_option = (\n",
            "      tf.contrib.tfprof.model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS)\n",
            "  tfprof_flops_option = tf.contrib.tfprof.model_analyzer.FLOAT_OPS_OPTIONS\n",
            "\n",
            "  # Batchnorm is usually folded during inference.\n",
            "  tfprof_vars_option['trim_name_regexes'] = ['.*BatchNorm.*']\n",
            "  # Initializer and Regularizer are only used in training.\n",
            "  tfprof_flops_option['trim_name_regexes'] = [\n",
            "      '.*BatchNorm.*', '.*Initializer.*', '.*Regularizer.*', '.*BiasAdd.*'\n",
            "  ]\n",
            "\n",
            "  tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
            "      graph,\n",
            "      tfprof_options=tfprof_vars_option)\n",
            "\n",
            "  tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
            "      graph,\n",
            "      tfprof_options=tfprof_flops_option)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4cIDbmjJxTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c1b9340-e747-4133-8d13-ba98480f5d3a"
      },
      "source": [
        "%%writefile updated_exporter.py\n",
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Functions to export object detection inference graph.\"\"\"\n",
        "import os\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.quantize.python import graph_matcher\n",
        "from tensorflow.core.protobuf import saver_pb2\n",
        "from tensorflow.python.tools import freeze_graph  # pylint: disable=g-direct-tensorflow-import\n",
        "from object_detection.builders import graph_rewriter_builder\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.core import standard_fields as fields\n",
        "from object_detection.data_decoders import tf_example_decoder\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import shape_utils\n",
        "from tensorflow.python.client import session\n",
        "from tensorflow.python.saved_model import signature_constants\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "freeze_graph_with_def_protos = freeze_graph.freeze_graph_with_def_protos\n",
        "\n",
        "\n",
        "def rewrite_nn_resize_op(is_quantized=False):\n",
        "  \"\"\"Replaces a custom nearest-neighbor resize op with the Tensorflow version.\n",
        "\n",
        "  Some graphs use this custom version for TPU-compatibility.\n",
        "\n",
        "  Args:\n",
        "    is_quantized: True if the default graph is quantized.\n",
        "  \"\"\"\n",
        "  def remove_nn():\n",
        "    \"\"\"Remove nearest neighbor upsampling structure and replace with TF op.\"\"\"\n",
        "    input_pattern = graph_matcher.OpTypePattern(\n",
        "        'FakeQuantWithMinMaxVars' if is_quantized else '*')\n",
        "    stack_1_pattern = graph_matcher.OpTypePattern(\n",
        "        'Pack', inputs=[input_pattern, input_pattern], ordered_inputs=False)\n",
        "    stack_2_pattern = graph_matcher.OpTypePattern(\n",
        "        'Pack', inputs=[stack_1_pattern, stack_1_pattern], ordered_inputs=False)\n",
        "    reshape_pattern = graph_matcher.OpTypePattern(\n",
        "        'Reshape', inputs=[stack_2_pattern, 'Const'], ordered_inputs=False)\n",
        "    consumer_pattern = graph_matcher.OpTypePattern(\n",
        "        'Add|AddV2|Max|Mul', inputs=[reshape_pattern, '*'],\n",
        "        ordered_inputs=False)\n",
        "\n",
        "    match_counter = 0\n",
        "    matcher = graph_matcher.GraphMatcher(consumer_pattern)\n",
        "    for match in matcher.match_graph(tf.get_default_graph()):\n",
        "      match_counter += 1\n",
        "      projection_op = match.get_op(input_pattern)\n",
        "      reshape_op = match.get_op(reshape_pattern)\n",
        "      consumer_op = match.get_op(consumer_pattern)\n",
        "      nn_resize = tf.image.resize_nearest_neighbor(\n",
        "          projection_op.outputs[0],\n",
        "          reshape_op.outputs[0].shape.dims[1:3],\n",
        "          align_corners=False,\n",
        "          name=os.path.split(reshape_op.name)[0] + '/resize_nearest_neighbor')\n",
        "\n",
        "      for index, op_input in enumerate(consumer_op.inputs):\n",
        "        if op_input == reshape_op.outputs[0]:\n",
        "          consumer_op._update_input(index, nn_resize)  # pylint: disable=protected-access\n",
        "          break\n",
        "\n",
        "    tf.logging.info('Found and fixed {} matches'.format(match_counter))\n",
        "    return match_counter\n",
        "\n",
        "  # Applying twice because both inputs to Add could be NN pattern\n",
        "  total_removals = 0\n",
        "  while remove_nn():\n",
        "    total_removals += 1\n",
        "    # This number is chosen based on the nas-fpn architecture.\n",
        "    if total_removals > 4:\n",
        "      raise ValueError('Graph removal encountered a infinite loop.')\n",
        "\n",
        "\n",
        "def replace_variable_values_with_moving_averages(graph,\n",
        "                                                 current_checkpoint_file,\n",
        "                                                 new_checkpoint_file,\n",
        "                                                 no_ema_collection=None):\n",
        "  \"\"\"Replaces variable values in the checkpoint with their moving averages.\n",
        "\n",
        "  If the current checkpoint has shadow variables maintaining moving averages of\n",
        "  the variables defined in the graph, this function generates a new checkpoint\n",
        "  where the variables contain the values of their moving averages.\n",
        "\n",
        "  Args:\n",
        "    graph: a tf.Graph object.\n",
        "    current_checkpoint_file: a checkpoint containing both original variables and\n",
        "      their moving averages.\n",
        "    new_checkpoint_file: file path to write a new checkpoint.\n",
        "    no_ema_collection: A list of namescope substrings to match the variables\n",
        "      to eliminate EMA.\n",
        "  \"\"\"\n",
        "  with graph.as_default():\n",
        "    variable_averages = tf.train.ExponentialMovingAverage(0.0)\n",
        "    ema_variables_to_restore = variable_averages.variables_to_restore()\n",
        "    ema_variables_to_restore = config_util.remove_unecessary_ema(\n",
        "        ema_variables_to_restore, no_ema_collection)\n",
        "    with tf.Session() as sess:\n",
        "      read_saver = tf.train.Saver(ema_variables_to_restore)\n",
        "      read_saver.restore(sess, current_checkpoint_file)\n",
        "      write_saver = tf.train.Saver()\n",
        "      write_saver.save(sess, new_checkpoint_file)\n",
        "\n",
        "\n",
        "def _image_tensor_input_placeholder(input_shape=None):\n",
        "  \"\"\"Returns input placeholder and a 4-D uint8 image tensor.\"\"\"\n",
        "  if input_shape is None:\n",
        "    input_shape = (None, None, None, 3)\n",
        "  input_tensor = tf.placeholder(\n",
        "      dtype=tf.uint8, shape=input_shape, name='image_tensor')\n",
        "  return input_tensor, input_tensor\n",
        "\n",
        "\n",
        "def _tf_example_input_placeholder(input_shape=None):\n",
        "  \"\"\"Returns input that accepts a batch of strings with tf examples.\n",
        "\n",
        "  Args:\n",
        "    input_shape: the shape to resize the output decoded images to (optional).\n",
        "\n",
        "  Returns:\n",
        "    a tuple of input placeholder and the output decoded images.\n",
        "  \"\"\"\n",
        "  batch_tf_example_placeholder = tf.placeholder(\n",
        "      tf.string, shape=[None], name='tf_example')\n",
        "  def decode(tf_example_string_tensor):\n",
        "    tensor_dict = tf_example_decoder.TfExampleDecoder().decode(\n",
        "        tf_example_string_tensor)\n",
        "    image_tensor = tensor_dict[fields.InputDataFields.image]\n",
        "    if input_shape is not None:\n",
        "      image_tensor = tf.image.resize(image_tensor, input_shape[1:3])\n",
        "    return image_tensor\n",
        "  return (batch_tf_example_placeholder,\n",
        "          shape_utils.static_or_dynamic_map_fn(\n",
        "              decode,\n",
        "              elems=batch_tf_example_placeholder,\n",
        "              dtype=tf.uint8,\n",
        "              parallel_iterations=32,\n",
        "              back_prop=False))\n",
        "\n",
        "\n",
        "def _encoded_image_string_tensor_input_placeholder(input_shape=None):\n",
        "  \"\"\"Returns input that accepts a batch of PNG or JPEG strings.\n",
        "\n",
        "  Args:\n",
        "    input_shape: the shape to resize the output decoded images to (optional).\n",
        "\n",
        "  Returns:\n",
        "    a tuple of input placeholder and the output decoded images.\n",
        "  \"\"\"\n",
        "  batch_image_str_placeholder = tf.placeholder(\n",
        "      dtype=tf.string,\n",
        "      shape=[None],\n",
        "      name='encoded_image_string_tensor')\n",
        "  def decode(encoded_image_string_tensor):\n",
        "    image_tensor = tf.image.decode_image(encoded_image_string_tensor,\n",
        "                                         channels=3)\n",
        "    image_tensor.set_shape((None, None, 3))\n",
        "    if input_shape is not None:\n",
        "      image_tensor = tf.image.resize(image_tensor, input_shape[1:3])\n",
        "    return image_tensor\n",
        "  return (batch_image_str_placeholder,\n",
        "          tf.map_fn(\n",
        "              decode,\n",
        "              elems=batch_image_str_placeholder,\n",
        "              dtype=tf.uint8,\n",
        "              parallel_iterations=32,\n",
        "              back_prop=False))\n",
        "\n",
        "\n",
        "input_placeholder_fn_map = {\n",
        "    'image_tensor': _image_tensor_input_placeholder,\n",
        "    'encoded_image_string_tensor':\n",
        "    _encoded_image_string_tensor_input_placeholder,\n",
        "    'tf_example': _tf_example_input_placeholder,\n",
        "}\n",
        "\n",
        "\n",
        "def add_output_tensor_nodes(postprocessed_tensors,\n",
        "                            output_collection_name='inference_op'):\n",
        "  \"\"\"Adds output nodes for detection boxes and scores.\n",
        "\n",
        "  Adds the following nodes for output tensors -\n",
        "    * num_detections: float32 tensor of shape [batch_size].\n",
        "    * detection_boxes: float32 tensor of shape [batch_size, num_boxes, 4]\n",
        "      containing detected boxes.\n",
        "    * detection_scores: float32 tensor of shape [batch_size, num_boxes]\n",
        "      containing scores for the detected boxes.\n",
        "    * detection_multiclass_scores: (Optional) float32 tensor of shape\n",
        "      [batch_size, num_boxes, num_classes_with_background] for containing class\n",
        "      score distribution for detected boxes including background if any.\n",
        "    * detection_features: (Optional) float32 tensor of shape\n",
        "      [batch, num_boxes, roi_height, roi_width, depth]\n",
        "      containing classifier features\n",
        "      for each detected box\n",
        "    * detection_classes: float32 tensor of shape [batch_size, num_boxes]\n",
        "      containing class predictions for the detected boxes.\n",
        "    * detection_keypoints: (Optional) float32 tensor of shape\n",
        "      [batch_size, num_boxes, num_keypoints, 2] containing keypoints for each\n",
        "      detection box.\n",
        "    * detection_masks: (Optional) float32 tensor of shape\n",
        "      [batch_size, num_boxes, mask_height, mask_width] containing masks for each\n",
        "      detection box.\n",
        "\n",
        "  Args:\n",
        "    postprocessed_tensors: a dictionary containing the following fields\n",
        "      'detection_boxes': [batch, max_detections, 4]\n",
        "      'detection_scores': [batch, max_detections]\n",
        "      'detection_multiclass_scores': [batch, max_detections,\n",
        "        num_classes_with_background]\n",
        "      'detection_features': [batch, num_boxes, roi_height, roi_width, depth]\n",
        "      'detection_classes': [batch, max_detections]\n",
        "      'detection_masks': [batch, max_detections, mask_height, mask_width]\n",
        "        (optional).\n",
        "      'detection_keypoints': [batch, max_detections, num_keypoints, 2]\n",
        "        (optional).\n",
        "      'num_detections': [batch]\n",
        "    output_collection_name: Name of collection to add output tensors to.\n",
        "\n",
        "  Returns:\n",
        "    A tensor dict containing the added output tensor nodes.\n",
        "  \"\"\"\n",
        "  detection_fields = fields.DetectionResultFields\n",
        "  label_id_offset = 1\n",
        "  boxes = postprocessed_tensors.get(detection_fields.detection_boxes)\n",
        "  scores = postprocessed_tensors.get(detection_fields.detection_scores)\n",
        "  multiclass_scores = postprocessed_tensors.get(\n",
        "      detection_fields.detection_multiclass_scores)\n",
        "  box_classifier_features = postprocessed_tensors.get(\n",
        "      detection_fields.detection_features)\n",
        "  raw_boxes = postprocessed_tensors.get(detection_fields.raw_detection_boxes)\n",
        "  raw_scores = postprocessed_tensors.get(detection_fields.raw_detection_scores)\n",
        "  classes = postprocessed_tensors.get(\n",
        "      detection_fields.detection_classes) + label_id_offset\n",
        "  keypoints = postprocessed_tensors.get(detection_fields.detection_keypoints)\n",
        "  masks = postprocessed_tensors.get(detection_fields.detection_masks)\n",
        "  num_detections = postprocessed_tensors.get(detection_fields.num_detections)\n",
        "  outputs = {}\n",
        "  outputs[detection_fields.detection_boxes] = tf.identity(\n",
        "      boxes, name=detection_fields.detection_boxes)\n",
        "  outputs[detection_fields.detection_scores] = tf.identity(\n",
        "      scores, name=detection_fields.detection_scores)\n",
        "  if multiclass_scores is not None:\n",
        "    outputs[detection_fields.detection_multiclass_scores] = tf.identity(\n",
        "        multiclass_scores, name=detection_fields.detection_multiclass_scores)\n",
        "  if box_classifier_features is not None:\n",
        "    outputs[detection_fields.detection_features] = tf.identity(\n",
        "        box_classifier_features,\n",
        "        name=detection_fields.detection_features)\n",
        "  outputs[detection_fields.detection_classes] = tf.identity(\n",
        "      classes, name=detection_fields.detection_classes)\n",
        "  outputs[detection_fields.num_detections] = tf.identity(\n",
        "      num_detections, name=detection_fields.num_detections)\n",
        "  if raw_boxes is not None:\n",
        "    outputs[detection_fields.raw_detection_boxes] = tf.identity(\n",
        "        raw_boxes, name=detection_fields.raw_detection_boxes)\n",
        "  if raw_scores is not None:\n",
        "    outputs[detection_fields.raw_detection_scores] = tf.identity(\n",
        "        raw_scores, name=detection_fields.raw_detection_scores)\n",
        "  if keypoints is not None:\n",
        "    outputs[detection_fields.detection_keypoints] = tf.identity(\n",
        "        keypoints, name=detection_fields.detection_keypoints)\n",
        "  if masks is not None:\n",
        "    outputs[detection_fields.detection_masks] = tf.identity(\n",
        "        masks, name=detection_fields.detection_masks)\n",
        "  for output_key in outputs:\n",
        "    tf.add_to_collection(output_collection_name, outputs[output_key])\n",
        "\n",
        "  return outputs\n",
        "\n",
        "\n",
        "def write_saved_model(saved_model_path,\n",
        "                       trained_checkpoint_prefix,\n",
        "                       inputs,\n",
        "                       outputs):\n",
        "  \"\"\"Writes SavedModel to disk.\n",
        "  Args:\n",
        "    saved_model_path: Path to write SavedModel.\n",
        "    trained_checkpoint_prefix: path to trained_checkpoint_prefix.\n",
        "    inputs: The input image tensor to use for detection.\n",
        "    outputs: A tensor dictionary containing the outputs of a DetectionModel.\n",
        "  \"\"\"\n",
        "  saver = tf.train.Saver()\n",
        "  with session.Session() as sess:\n",
        "    saver.restore(sess, trained_checkpoint_prefix)\n",
        "    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n",
        "\n",
        "    tensor_info_inputs = {\n",
        "          'inputs': tf.saved_model.utils.build_tensor_info(inputs)}\n",
        "    tensor_info_outputs = {}\n",
        "    for k, v in outputs.items():\n",
        "      tensor_info_outputs[k] = tf.saved_model.utils.build_tensor_info(v)\n",
        "\n",
        "    detection_signature = (\n",
        "        tf.saved_model.signature_def_utils.build_signature_def(\n",
        "              inputs=tensor_info_inputs,\n",
        "              outputs=tensor_info_outputs,\n",
        "              method_name=signature_constants.PREDICT_METHOD_NAME))\n",
        "\n",
        "    builder.add_meta_graph_and_variables(\n",
        "          sess, [tf.saved_model.tag_constants.SERVING],\n",
        "          signature_def_map={\n",
        "              'detection_signature':\n",
        "                  detection_signature,\n",
        "              signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
        "                  detection_signature,\n",
        "          },\n",
        "      )\n",
        "    builder.save()\n",
        "\n",
        "\n",
        "def write_graph_and_checkpoint(inference_graph_def,\n",
        "                               model_path,\n",
        "                               input_saver_def,\n",
        "                               trained_checkpoint_prefix):\n",
        "  \"\"\"Writes the graph and the checkpoint into disk.\"\"\"\n",
        "  for node in inference_graph_def.node:\n",
        "    node.device = ''\n",
        "  with tf.Graph().as_default():\n",
        "    tf.import_graph_def(inference_graph_def, name='')\n",
        "    with tf.Session() as sess:\n",
        "      saver = tf.train.Saver(\n",
        "          saver_def=input_saver_def, save_relative_paths=True)\n",
        "      saver.restore(sess, trained_checkpoint_prefix)\n",
        "      saver.save(sess, model_path)\n",
        "\n",
        "\n",
        "def _get_outputs_from_inputs(input_tensors, detection_model,\n",
        "                             output_collection_name):\n",
        "  inputs = tf.cast(input_tensors, dtype=tf.float32)\n",
        "  preprocessed_inputs, true_image_shapes = detection_model.preprocess(inputs)\n",
        "  output_tensors = detection_model.predict(\n",
        "      preprocessed_inputs, true_image_shapes)\n",
        "  postprocessed_tensors = detection_model.postprocess(\n",
        "      output_tensors, true_image_shapes)\n",
        "  return add_output_tensor_nodes(postprocessed_tensors,\n",
        "                                 output_collection_name)\n",
        "\n",
        "\n",
        "def build_detection_graph(input_type, detection_model, input_shape,\n",
        "                          output_collection_name, graph_hook_fn):\n",
        "  \"\"\"Build the detection graph.\"\"\"\n",
        "  if input_type not in input_placeholder_fn_map:\n",
        "    raise ValueError('Unknown input type: {}'.format(input_type))\n",
        "  placeholder_args = {}\n",
        "  if input_shape is not None:\n",
        "    if (input_type != 'image_tensor' and\n",
        "        input_type != 'encoded_image_string_tensor' and\n",
        "        input_type != 'tf_example'):\n",
        "      raise ValueError('Can only specify input shape for `image_tensor`, '\n",
        "                       '`encoded_image_string_tensor`, or `tf_example` '\n",
        "                       'inputs.')\n",
        "    placeholder_args['input_shape'] = input_shape\n",
        "  placeholder_tensor, input_tensors = input_placeholder_fn_map[input_type](\n",
        "      **placeholder_args)\n",
        "  outputs = _get_outputs_from_inputs(\n",
        "      input_tensors=input_tensors,\n",
        "      detection_model=detection_model,\n",
        "      output_collection_name=output_collection_name)\n",
        "\n",
        "  # Add global step to the graph.\n",
        "  slim.get_or_create_global_step()\n",
        "\n",
        "  if graph_hook_fn: graph_hook_fn()\n",
        "\n",
        "  return outputs, placeholder_tensor\n",
        "\n",
        "\n",
        "def _export_inference_graph(input_type,\n",
        "                            detection_model,\n",
        "                            use_moving_averages,\n",
        "                            trained_checkpoint_prefix,\n",
        "                            output_directory,\n",
        "                            additional_output_tensor_names=None,\n",
        "                            input_shape=None,\n",
        "                            output_collection_name='inference_op',\n",
        "                            graph_hook_fn=None,\n",
        "                            write_inference_graph=False,\n",
        "                            temp_checkpoint_prefix=''):\n",
        "  \"\"\"Export helper.\"\"\"\n",
        "  tf.gfile.MakeDirs(output_directory)\n",
        "  frozen_graph_path = os.path.join(output_directory,\n",
        "                                   'frozen_inference_graph.pb')\n",
        "  saved_model_path = os.path.join(output_directory, 'saved_model')\n",
        "  model_path = os.path.join(output_directory, 'model.ckpt')\n",
        "\n",
        "  outputs, placeholder_tensor = build_detection_graph(\n",
        "      input_type=input_type,\n",
        "      detection_model=detection_model,\n",
        "      input_shape=input_shape,\n",
        "      output_collection_name=output_collection_name,\n",
        "      graph_hook_fn=graph_hook_fn)\n",
        "\n",
        "  profile_inference_graph(tf.get_default_graph())\n",
        "  saver_kwargs = {}\n",
        "  if use_moving_averages:\n",
        "    if not temp_checkpoint_prefix:\n",
        "      # This check is to be compatible with both version of SaverDef.\n",
        "      if os.path.isfile(trained_checkpoint_prefix):\n",
        "        saver_kwargs['write_version'] = saver_pb2.SaverDef.V1\n",
        "        temp_checkpoint_prefix = tempfile.NamedTemporaryFile().name\n",
        "      else:\n",
        "        temp_checkpoint_prefix = tempfile.mkdtemp()\n",
        "    replace_variable_values_with_moving_averages(\n",
        "        tf.get_default_graph(), trained_checkpoint_prefix,\n",
        "        temp_checkpoint_prefix)\n",
        "    checkpoint_to_use = temp_checkpoint_prefix\n",
        "  else:\n",
        "    checkpoint_to_use = trained_checkpoint_prefix\n",
        "\n",
        "  saver = tf.train.Saver(**saver_kwargs)\n",
        "  input_saver_def = saver.as_saver_def()\n",
        "\n",
        "  write_graph_and_checkpoint(\n",
        "      inference_graph_def=tf.get_default_graph().as_graph_def(),\n",
        "      model_path=model_path,\n",
        "      input_saver_def=input_saver_def,\n",
        "      trained_checkpoint_prefix=checkpoint_to_use)\n",
        "  if write_inference_graph:\n",
        "    inference_graph_def = tf.get_default_graph().as_graph_def()\n",
        "    inference_graph_path = os.path.join(output_directory,\n",
        "                                        'inference_graph.pbtxt')\n",
        "    for node in inference_graph_def.node:\n",
        "      node.device = ''\n",
        "    with tf.gfile.GFile(inference_graph_path, 'wb') as f:\n",
        "      f.write(str(inference_graph_def))\n",
        "\n",
        "  if additional_output_tensor_names is not None:\n",
        "    output_node_names = ','.join(outputs.keys()+additional_output_tensor_names)\n",
        "  else:\n",
        "    output_node_names = ','.join(outputs.keys())\n",
        "\n",
        "  frozen_graph_def = freeze_graph.freeze_graph_with_def_protos(\n",
        "      input_graph_def=tf.get_default_graph().as_graph_def(),\n",
        "      input_saver_def=input_saver_def,\n",
        "      input_checkpoint=checkpoint_to_use,\n",
        "      output_node_names=output_node_names,\n",
        "      restore_op_name='save/restore_all',\n",
        "      filename_tensor_name='save/Const:0',\n",
        "      output_graph=frozen_graph_path,\n",
        "      clear_devices=True,\n",
        "      initializer_nodes='')\n",
        "\n",
        "  write_saved_model(saved_model_path, trained_checkpoint_prefix,\n",
        "                    placeholder_tensor, outputs)\n",
        "\n",
        "\n",
        "def export_inference_graph(input_type,\n",
        "                           pipeline_config,\n",
        "                           trained_checkpoint_prefix,\n",
        "                           output_directory,\n",
        "                           input_shape=None,\n",
        "                           output_collection_name='inference_op',\n",
        "                           additional_output_tensor_names=None,\n",
        "                           write_inference_graph=False):\n",
        "  \"\"\"Exports inference graph for the model specified in the pipeline config.\n",
        "\n",
        "  Args:\n",
        "    input_type: Type of input for the graph. Can be one of ['image_tensor',\n",
        "      'encoded_image_string_tensor', 'tf_example'].\n",
        "    pipeline_config: pipeline_pb2.TrainAndEvalPipelineConfig proto.\n",
        "    trained_checkpoint_prefix: Path to the trained checkpoint file.\n",
        "    output_directory: Path to write outputs.\n",
        "    input_shape: Sets a fixed shape for an `image_tensor` input. If not\n",
        "      specified, will default to [None, None, None, 3].\n",
        "    output_collection_name: Name of collection to add output tensors to.\n",
        "      If None, does not add output tensors to a collection.\n",
        "    additional_output_tensor_names: list of additional output\n",
        "      tensors to include in the frozen graph.\n",
        "    write_inference_graph: If true, writes inference graph to disk.\n",
        "  \"\"\"\n",
        "  detection_model = model_builder.build(pipeline_config.model,\n",
        "                                        is_training=False)\n",
        "  graph_rewriter_fn = None\n",
        "  if pipeline_config.HasField('graph_rewriter'):\n",
        "    graph_rewriter_config = pipeline_config.graph_rewriter\n",
        "    graph_rewriter_fn = graph_rewriter_builder.build(graph_rewriter_config,\n",
        "                                                     is_training=False)\n",
        "  _export_inference_graph(\n",
        "      input_type,\n",
        "      detection_model,\n",
        "      pipeline_config.eval_config.use_moving_averages,\n",
        "      trained_checkpoint_prefix,\n",
        "      output_directory,\n",
        "      additional_output_tensor_names,\n",
        "      input_shape,\n",
        "      output_collection_name,\n",
        "      graph_hook_fn=graph_rewriter_fn,\n",
        "      write_inference_graph=write_inference_graph)\n",
        "  pipeline_config.eval_config.use_moving_averages = False\n",
        "  config_util.save_pipeline_config(pipeline_config, output_directory)\n",
        "\n",
        "\n",
        "def profile_inference_graph(graph):\n",
        "  \"\"\"Profiles the inference graph.\n",
        "\n",
        "  Prints model parameters and computation FLOPs given an inference graph.\n",
        "  BatchNorms are excluded from the parameter count due to the fact that\n",
        "  BatchNorms are usually folded. BatchNorm, Initializer, Regularizer\n",
        "  and BiasAdd are not considered in FLOP count.\n",
        "\n",
        "  Args:\n",
        "    graph: the inference graph.\n",
        "  \"\"\"\n",
        "  tfprof_vars_option = (\n",
        "      tf.contrib.tfprof.model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS)\n",
        "  tfprof_flops_option = tf.contrib.tfprof.model_analyzer.FLOAT_OPS_OPTIONS\n",
        "\n",
        "  # Batchnorm is usually folded during inference.\n",
        "  tfprof_vars_option['trim_name_regexes'] = ['.*BatchNorm.*']\n",
        "  # Initializer and Regularizer are only used in training.\n",
        "  tfprof_flops_option['trim_name_regexes'] = [\n",
        "      '.*BatchNorm.*', '.*Initializer.*', '.*Regularizer.*', '.*BiasAdd.*'\n",
        "  ]\n",
        "\n",
        "  tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
        "      graph,\n",
        "      tfprof_options=tfprof_vars_option)\n",
        "\n",
        "  tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
        "      graph,\n",
        "      tfprof_options=tfprof_flops_option)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting updated_exporter.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzeXPkFmLEPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d99f36df-e37a-4c68-c1b1-a24a59afef29"
      },
      "source": [
        "!cat updated_exporter.py"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
            "#\n",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "# you may not use this file except in compliance with the License.\n",
            "# You may obtain a copy of the License at\n",
            "#\n",
            "#     http://www.apache.org/licenses/LICENSE-2.0\n",
            "#\n",
            "# Unless required by applicable law or agreed to in writing, software\n",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "# See the License for the specific language governing permissions and\n",
            "# limitations under the License.\n",
            "# ==============================================================================\n",
            "\n",
            "\"\"\"Functions to export object detection inference graph.\"\"\"\n",
            "import os\n",
            "import tempfile\n",
            "import tensorflow as tf\n",
            "from tensorflow.contrib.quantize.python import graph_matcher\n",
            "from tensorflow.core.protobuf import saver_pb2\n",
            "from tensorflow.python.tools import freeze_graph  # pylint: disable=g-direct-tensorflow-import\n",
            "from object_detection.builders import graph_rewriter_builder\n",
            "from object_detection.builders import model_builder\n",
            "from object_detection.core import standard_fields as fields\n",
            "from object_detection.data_decoders import tf_example_decoder\n",
            "from object_detection.utils import config_util\n",
            "from object_detection.utils import shape_utils\n",
            "from tensorflow.python.client import session\n",
            "\n",
            "slim = tf.contrib.slim\n",
            "\n",
            "freeze_graph_with_def_protos = freeze_graph.freeze_graph_with_def_protos\n",
            "\n",
            "\n",
            "def rewrite_nn_resize_op(is_quantized=False):\n",
            "  \"\"\"Replaces a custom nearest-neighbor resize op with the Tensorflow version.\n",
            "\n",
            "  Some graphs use this custom version for TPU-compatibility.\n",
            "\n",
            "  Args:\n",
            "    is_quantized: True if the default graph is quantized.\n",
            "  \"\"\"\n",
            "  def remove_nn():\n",
            "    \"\"\"Remove nearest neighbor upsampling structure and replace with TF op.\"\"\"\n",
            "    input_pattern = graph_matcher.OpTypePattern(\n",
            "        'FakeQuantWithMinMaxVars' if is_quantized else '*')\n",
            "    stack_1_pattern = graph_matcher.OpTypePattern(\n",
            "        'Pack', inputs=[input_pattern, input_pattern], ordered_inputs=False)\n",
            "    stack_2_pattern = graph_matcher.OpTypePattern(\n",
            "        'Pack', inputs=[stack_1_pattern, stack_1_pattern], ordered_inputs=False)\n",
            "    reshape_pattern = graph_matcher.OpTypePattern(\n",
            "        'Reshape', inputs=[stack_2_pattern, 'Const'], ordered_inputs=False)\n",
            "    consumer_pattern = graph_matcher.OpTypePattern(\n",
            "        'Add|AddV2|Max|Mul', inputs=[reshape_pattern, '*'],\n",
            "        ordered_inputs=False)\n",
            "\n",
            "    match_counter = 0\n",
            "    matcher = graph_matcher.GraphMatcher(consumer_pattern)\n",
            "    for match in matcher.match_graph(tf.get_default_graph()):\n",
            "      match_counter += 1\n",
            "      projection_op = match.get_op(input_pattern)\n",
            "      reshape_op = match.get_op(reshape_pattern)\n",
            "      consumer_op = match.get_op(consumer_pattern)\n",
            "      nn_resize = tf.image.resize_nearest_neighbor(\n",
            "          projection_op.outputs[0],\n",
            "          reshape_op.outputs[0].shape.dims[1:3],\n",
            "          align_corners=False,\n",
            "          name=os.path.split(reshape_op.name)[0] + '/resize_nearest_neighbor')\n",
            "\n",
            "      for index, op_input in enumerate(consumer_op.inputs):\n",
            "        if op_input == reshape_op.outputs[0]:\n",
            "          consumer_op._update_input(index, nn_resize)  # pylint: disable=protected-access\n",
            "          break\n",
            "\n",
            "    tf.logging.info('Found and fixed {} matches'.format(match_counter))\n",
            "    return match_counter\n",
            "\n",
            "  # Applying twice because both inputs to Add could be NN pattern\n",
            "  total_removals = 0\n",
            "  while remove_nn():\n",
            "    total_removals += 1\n",
            "    # This number is chosen based on the nas-fpn architecture.\n",
            "    if total_removals > 4:\n",
            "      raise ValueError('Graph removal encountered a infinite loop.')\n",
            "\n",
            "\n",
            "def replace_variable_values_with_moving_averages(graph,\n",
            "                                                 current_checkpoint_file,\n",
            "                                                 new_checkpoint_file,\n",
            "                                                 no_ema_collection=None):\n",
            "  \"\"\"Replaces variable values in the checkpoint with their moving averages.\n",
            "\n",
            "  If the current checkpoint has shadow variables maintaining moving averages of\n",
            "  the variables defined in the graph, this function generates a new checkpoint\n",
            "  where the variables contain the values of their moving averages.\n",
            "\n",
            "  Args:\n",
            "    graph: a tf.Graph object.\n",
            "    current_checkpoint_file: a checkpoint containing both original variables and\n",
            "      their moving averages.\n",
            "    new_checkpoint_file: file path to write a new checkpoint.\n",
            "    no_ema_collection: A list of namescope substrings to match the variables\n",
            "      to eliminate EMA.\n",
            "  \"\"\"\n",
            "  with graph.as_default():\n",
            "    variable_averages = tf.train.ExponentialMovingAverage(0.0)\n",
            "    ema_variables_to_restore = variable_averages.variables_to_restore()\n",
            "    ema_variables_to_restore = config_util.remove_unecessary_ema(\n",
            "        ema_variables_to_restore, no_ema_collection)\n",
            "    with tf.Session() as sess:\n",
            "      read_saver = tf.train.Saver(ema_variables_to_restore)\n",
            "      read_saver.restore(sess, current_checkpoint_file)\n",
            "      write_saver = tf.train.Saver()\n",
            "      write_saver.save(sess, new_checkpoint_file)\n",
            "\n",
            "\n",
            "def _image_tensor_input_placeholder(input_shape=None):\n",
            "  \"\"\"Returns input placeholder and a 4-D uint8 image tensor.\"\"\"\n",
            "  if input_shape is None:\n",
            "    input_shape = (None, None, None, 3)\n",
            "  input_tensor = tf.placeholder(\n",
            "      dtype=tf.uint8, shape=input_shape, name='image_tensor')\n",
            "  return input_tensor, input_tensor\n",
            "\n",
            "\n",
            "def _tf_example_input_placeholder(input_shape=None):\n",
            "  \"\"\"Returns input that accepts a batch of strings with tf examples.\n",
            "\n",
            "  Args:\n",
            "    input_shape: the shape to resize the output decoded images to (optional).\n",
            "\n",
            "  Returns:\n",
            "    a tuple of input placeholder and the output decoded images.\n",
            "  \"\"\"\n",
            "  batch_tf_example_placeholder = tf.placeholder(\n",
            "      tf.string, shape=[None], name='tf_example')\n",
            "  def decode(tf_example_string_tensor):\n",
            "    tensor_dict = tf_example_decoder.TfExampleDecoder().decode(\n",
            "        tf_example_string_tensor)\n",
            "    image_tensor = tensor_dict[fields.InputDataFields.image]\n",
            "    if input_shape is not None:\n",
            "      image_tensor = tf.image.resize(image_tensor, input_shape[1:3])\n",
            "    return image_tensor\n",
            "  return (batch_tf_example_placeholder,\n",
            "          shape_utils.static_or_dynamic_map_fn(\n",
            "              decode,\n",
            "              elems=batch_tf_example_placeholder,\n",
            "              dtype=tf.uint8,\n",
            "              parallel_iterations=32,\n",
            "              back_prop=False))\n",
            "\n",
            "\n",
            "def _encoded_image_string_tensor_input_placeholder(input_shape=None):\n",
            "  \"\"\"Returns input that accepts a batch of PNG or JPEG strings.\n",
            "\n",
            "  Args:\n",
            "    input_shape: the shape to resize the output decoded images to (optional).\n",
            "\n",
            "  Returns:\n",
            "    a tuple of input placeholder and the output decoded images.\n",
            "  \"\"\"\n",
            "  batch_image_str_placeholder = tf.placeholder(\n",
            "      dtype=tf.string,\n",
            "      shape=[None],\n",
            "      name='encoded_image_string_tensor')\n",
            "  def decode(encoded_image_string_tensor):\n",
            "    image_tensor = tf.image.decode_image(encoded_image_string_tensor,\n",
            "                                         channels=3)\n",
            "    image_tensor.set_shape((None, None, 3))\n",
            "    if input_shape is not None:\n",
            "      image_tensor = tf.image.resize(image_tensor, input_shape[1:3])\n",
            "    return image_tensor\n",
            "  return (batch_image_str_placeholder,\n",
            "          tf.map_fn(\n",
            "              decode,\n",
            "              elems=batch_image_str_placeholder,\n",
            "              dtype=tf.uint8,\n",
            "              parallel_iterations=32,\n",
            "              back_prop=False))\n",
            "\n",
            "\n",
            "input_placeholder_fn_map = {\n",
            "    'image_tensor': _image_tensor_input_placeholder,\n",
            "    'encoded_image_string_tensor':\n",
            "    _encoded_image_string_tensor_input_placeholder,\n",
            "    'tf_example': _tf_example_input_placeholder,\n",
            "}\n",
            "\n",
            "\n",
            "def add_output_tensor_nodes(postprocessed_tensors,\n",
            "                            output_collection_name='inference_op'):\n",
            "  \"\"\"Adds output nodes for detection boxes and scores.\n",
            "\n",
            "  Adds the following nodes for output tensors -\n",
            "    * num_detections: float32 tensor of shape [batch_size].\n",
            "    * detection_boxes: float32 tensor of shape [batch_size, num_boxes, 4]\n",
            "      containing detected boxes.\n",
            "    * detection_scores: float32 tensor of shape [batch_size, num_boxes]\n",
            "      containing scores for the detected boxes.\n",
            "    * detection_multiclass_scores: (Optional) float32 tensor of shape\n",
            "      [batch_size, num_boxes, num_classes_with_background] for containing class\n",
            "      score distribution for detected boxes including background if any.\n",
            "    * detection_features: (Optional) float32 tensor of shape\n",
            "      [batch, num_boxes, roi_height, roi_width, depth]\n",
            "      containing classifier features\n",
            "      for each detected box\n",
            "    * detection_classes: float32 tensor of shape [batch_size, num_boxes]\n",
            "      containing class predictions for the detected boxes.\n",
            "    * detection_keypoints: (Optional) float32 tensor of shape\n",
            "      [batch_size, num_boxes, num_keypoints, 2] containing keypoints for each\n",
            "      detection box.\n",
            "    * detection_masks: (Optional) float32 tensor of shape\n",
            "      [batch_size, num_boxes, mask_height, mask_width] containing masks for each\n",
            "      detection box.\n",
            "\n",
            "  Args:\n",
            "    postprocessed_tensors: a dictionary containing the following fields\n",
            "      'detection_boxes': [batch, max_detections, 4]\n",
            "      'detection_scores': [batch, max_detections]\n",
            "      'detection_multiclass_scores': [batch, max_detections,\n",
            "        num_classes_with_background]\n",
            "      'detection_features': [batch, num_boxes, roi_height, roi_width, depth]\n",
            "      'detection_classes': [batch, max_detections]\n",
            "      'detection_masks': [batch, max_detections, mask_height, mask_width]\n",
            "        (optional).\n",
            "      'detection_keypoints': [batch, max_detections, num_keypoints, 2]\n",
            "        (optional).\n",
            "      'num_detections': [batch]\n",
            "    output_collection_name: Name of collection to add output tensors to.\n",
            "\n",
            "  Returns:\n",
            "    A tensor dict containing the added output tensor nodes.\n",
            "  \"\"\"\n",
            "  detection_fields = fields.DetectionResultFields\n",
            "  label_id_offset = 1\n",
            "  boxes = postprocessed_tensors.get(detection_fields.detection_boxes)\n",
            "  scores = postprocessed_tensors.get(detection_fields.detection_scores)\n",
            "  multiclass_scores = postprocessed_tensors.get(\n",
            "      detection_fields.detection_multiclass_scores)\n",
            "  box_classifier_features = postprocessed_tensors.get(\n",
            "      detection_fields.detection_features)\n",
            "  raw_boxes = postprocessed_tensors.get(detection_fields.raw_detection_boxes)\n",
            "  raw_scores = postprocessed_tensors.get(detection_fields.raw_detection_scores)\n",
            "  classes = postprocessed_tensors.get(\n",
            "      detection_fields.detection_classes) + label_id_offset\n",
            "  keypoints = postprocessed_tensors.get(detection_fields.detection_keypoints)\n",
            "  masks = postprocessed_tensors.get(detection_fields.detection_masks)\n",
            "  num_detections = postprocessed_tensors.get(detection_fields.num_detections)\n",
            "  outputs = {}\n",
            "  outputs[detection_fields.detection_boxes] = tf.identity(\n",
            "      boxes, name=detection_fields.detection_boxes)\n",
            "  outputs[detection_fields.detection_scores] = tf.identity(\n",
            "      scores, name=detection_fields.detection_scores)\n",
            "  if multiclass_scores is not None:\n",
            "    outputs[detection_fields.detection_multiclass_scores] = tf.identity(\n",
            "        multiclass_scores, name=detection_fields.detection_multiclass_scores)\n",
            "  if box_classifier_features is not None:\n",
            "    outputs[detection_fields.detection_features] = tf.identity(\n",
            "        box_classifier_features,\n",
            "        name=detection_fields.detection_features)\n",
            "  outputs[detection_fields.detection_classes] = tf.identity(\n",
            "      classes, name=detection_fields.detection_classes)\n",
            "  outputs[detection_fields.num_detections] = tf.identity(\n",
            "      num_detections, name=detection_fields.num_detections)\n",
            "  if raw_boxes is not None:\n",
            "    outputs[detection_fields.raw_detection_boxes] = tf.identity(\n",
            "        raw_boxes, name=detection_fields.raw_detection_boxes)\n",
            "  if raw_scores is not None:\n",
            "    outputs[detection_fields.raw_detection_scores] = tf.identity(\n",
            "        raw_scores, name=detection_fields.raw_detection_scores)\n",
            "  if keypoints is not None:\n",
            "    outputs[detection_fields.detection_keypoints] = tf.identity(\n",
            "        keypoints, name=detection_fields.detection_keypoints)\n",
            "  if masks is not None:\n",
            "    outputs[detection_fields.detection_masks] = tf.identity(\n",
            "        masks, name=detection_fields.detection_masks)\n",
            "  for output_key in outputs:\n",
            "    tf.add_to_collection(output_collection_name, outputs[output_key])\n",
            "\n",
            "  return outputs\n",
            "\n",
            "\n",
            "def write_saved_model(saved_model_path,\n",
            "                       trained_checkpoint_prefix,\n",
            "                       inputs,\n",
            "                       outputs):\n",
            "  \"\"\"Writes SavedModel to disk.\n",
            "  Args:\n",
            "    saved_model_path: Path to write SavedModel.\n",
            "    trained_checkpoint_prefix: path to trained_checkpoint_prefix.\n",
            "    inputs: The input image tensor to use for detection.\n",
            "    outputs: A tensor dictionary containing the outputs of a DetectionModel.\n",
            "  \"\"\"\n",
            "  saver = tf.train.Saver()\n",
            "  with session.Session() as sess:\n",
            "    saver.restore(sess, trained_checkpoint_prefix)\n",
            "    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n",
            "\n",
            "    tensor_info_inputs = {\n",
            "          'inputs': tf.saved_model.utils.build_tensor_info(inputs)}\n",
            "    tensor_info_outputs = {}\n",
            "    for k, v in outputs.items():\n",
            "      tensor_info_outputs[k] = tf.saved_model.utils.build_tensor_info(v)\n",
            "\n",
            "    detection_signature = (\n",
            "        tf.saved_model.signature_def_utils.build_signature_def(\n",
            "              inputs=tensor_info_inputs,\n",
            "              outputs=tensor_info_outputs,\n",
            "              method_name=signature_constants.PREDICT_METHOD_NAME))\n",
            "\n",
            "    builder.add_meta_graph_and_variables(\n",
            "          sess, [tf.saved_model.tag_constants.SERVING],\n",
            "          signature_def_map={\n",
            "              'detection_signature':\n",
            "                  detection_signature,\n",
            "              signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
            "                  detection_signature,\n",
            "          },\n",
            "      )\n",
            "    builder.save()\n",
            "\n",
            "\n",
            "def write_graph_and_checkpoint(inference_graph_def,\n",
            "                               model_path,\n",
            "                               input_saver_def,\n",
            "                               trained_checkpoint_prefix):\n",
            "  \"\"\"Writes the graph and the checkpoint into disk.\"\"\"\n",
            "  for node in inference_graph_def.node:\n",
            "    node.device = ''\n",
            "  with tf.Graph().as_default():\n",
            "    tf.import_graph_def(inference_graph_def, name='')\n",
            "    with tf.Session() as sess:\n",
            "      saver = tf.train.Saver(\n",
            "          saver_def=input_saver_def, save_relative_paths=True)\n",
            "      saver.restore(sess, trained_checkpoint_prefix)\n",
            "      saver.save(sess, model_path)\n",
            "\n",
            "\n",
            "def _get_outputs_from_inputs(input_tensors, detection_model,\n",
            "                             output_collection_name):\n",
            "  inputs = tf.cast(input_tensors, dtype=tf.float32)\n",
            "  preprocessed_inputs, true_image_shapes = detection_model.preprocess(inputs)\n",
            "  output_tensors = detection_model.predict(\n",
            "      preprocessed_inputs, true_image_shapes)\n",
            "  postprocessed_tensors = detection_model.postprocess(\n",
            "      output_tensors, true_image_shapes)\n",
            "  return add_output_tensor_nodes(postprocessed_tensors,\n",
            "                                 output_collection_name)\n",
            "\n",
            "\n",
            "def build_detection_graph(input_type, detection_model, input_shape,\n",
            "                          output_collection_name, graph_hook_fn):\n",
            "  \"\"\"Build the detection graph.\"\"\"\n",
            "  if input_type not in input_placeholder_fn_map:\n",
            "    raise ValueError('Unknown input type: {}'.format(input_type))\n",
            "  placeholder_args = {}\n",
            "  if input_shape is not None:\n",
            "    if (input_type != 'image_tensor' and\n",
            "        input_type != 'encoded_image_string_tensor' and\n",
            "        input_type != 'tf_example'):\n",
            "      raise ValueError('Can only specify input shape for `image_tensor`, '\n",
            "                       '`encoded_image_string_tensor`, or `tf_example` '\n",
            "                       'inputs.')\n",
            "    placeholder_args['input_shape'] = input_shape\n",
            "  placeholder_tensor, input_tensors = input_placeholder_fn_map[input_type](\n",
            "      **placeholder_args)\n",
            "  outputs = _get_outputs_from_inputs(\n",
            "      input_tensors=input_tensors,\n",
            "      detection_model=detection_model,\n",
            "      output_collection_name=output_collection_name)\n",
            "\n",
            "  # Add global step to the graph.\n",
            "  slim.get_or_create_global_step()\n",
            "\n",
            "  if graph_hook_fn: graph_hook_fn()\n",
            "\n",
            "  return outputs, placeholder_tensor\n",
            "\n",
            "\n",
            "def _export_inference_graph(input_type,\n",
            "                            detection_model,\n",
            "                            use_moving_averages,\n",
            "                            trained_checkpoint_prefix,\n",
            "                            output_directory,\n",
            "                            additional_output_tensor_names=None,\n",
            "                            input_shape=None,\n",
            "                            output_collection_name='inference_op',\n",
            "                            graph_hook_fn=None,\n",
            "                            write_inference_graph=False,\n",
            "                            temp_checkpoint_prefix=''):\n",
            "  \"\"\"Export helper.\"\"\"\n",
            "  tf.gfile.MakeDirs(output_directory)\n",
            "  frozen_graph_path = os.path.join(output_directory,\n",
            "                                   'frozen_inference_graph.pb')\n",
            "  saved_model_path = os.path.join(output_directory, 'saved_model')\n",
            "  model_path = os.path.join(output_directory, 'model.ckpt')\n",
            "\n",
            "  outputs, placeholder_tensor = build_detection_graph(\n",
            "      input_type=input_type,\n",
            "      detection_model=detection_model,\n",
            "      input_shape=input_shape,\n",
            "      output_collection_name=output_collection_name,\n",
            "      graph_hook_fn=graph_hook_fn)\n",
            "\n",
            "  profile_inference_graph(tf.get_default_graph())\n",
            "  saver_kwargs = {}\n",
            "  if use_moving_averages:\n",
            "    if not temp_checkpoint_prefix:\n",
            "      # This check is to be compatible with both version of SaverDef.\n",
            "      if os.path.isfile(trained_checkpoint_prefix):\n",
            "        saver_kwargs['write_version'] = saver_pb2.SaverDef.V1\n",
            "        temp_checkpoint_prefix = tempfile.NamedTemporaryFile().name\n",
            "      else:\n",
            "        temp_checkpoint_prefix = tempfile.mkdtemp()\n",
            "    replace_variable_values_with_moving_averages(\n",
            "        tf.get_default_graph(), trained_checkpoint_prefix,\n",
            "        temp_checkpoint_prefix)\n",
            "    checkpoint_to_use = temp_checkpoint_prefix\n",
            "  else:\n",
            "    checkpoint_to_use = trained_checkpoint_prefix\n",
            "\n",
            "  saver = tf.train.Saver(**saver_kwargs)\n",
            "  input_saver_def = saver.as_saver_def()\n",
            "\n",
            "  write_graph_and_checkpoint(\n",
            "      inference_graph_def=tf.get_default_graph().as_graph_def(),\n",
            "      model_path=model_path,\n",
            "      input_saver_def=input_saver_def,\n",
            "      trained_checkpoint_prefix=checkpoint_to_use)\n",
            "  if write_inference_graph:\n",
            "    inference_graph_def = tf.get_default_graph().as_graph_def()\n",
            "    inference_graph_path = os.path.join(output_directory,\n",
            "                                        'inference_graph.pbtxt')\n",
            "    for node in inference_graph_def.node:\n",
            "      node.device = ''\n",
            "    with tf.gfile.GFile(inference_graph_path, 'wb') as f:\n",
            "      f.write(str(inference_graph_def))\n",
            "\n",
            "  if additional_output_tensor_names is not None:\n",
            "    output_node_names = ','.join(outputs.keys()+additional_output_tensor_names)\n",
            "  else:\n",
            "    output_node_names = ','.join(outputs.keys())\n",
            "\n",
            "  frozen_graph_def = freeze_graph.freeze_graph_with_def_protos(\n",
            "      input_graph_def=tf.get_default_graph().as_graph_def(),\n",
            "      input_saver_def=input_saver_def,\n",
            "      input_checkpoint=checkpoint_to_use,\n",
            "      output_node_names=output_node_names,\n",
            "      restore_op_name='save/restore_all',\n",
            "      filename_tensor_name='save/Const:0',\n",
            "      output_graph=frozen_graph_path,\n",
            "      clear_devices=True,\n",
            "      initializer_nodes='')\n",
            "\n",
            "  write_saved_model(saved_model_path, trained_checkpoint_prefix,\n",
            "                    placeholder_tensor, outputs)\n",
            "\n",
            "\n",
            "def export_inference_graph(input_type,\n",
            "                           pipeline_config,\n",
            "                           trained_checkpoint_prefix,\n",
            "                           output_directory,\n",
            "                           input_shape=None,\n",
            "                           output_collection_name='inference_op',\n",
            "                           additional_output_tensor_names=None,\n",
            "                           write_inference_graph=False):\n",
            "  \"\"\"Exports inference graph for the model specified in the pipeline config.\n",
            "\n",
            "  Args:\n",
            "    input_type: Type of input for the graph. Can be one of ['image_tensor',\n",
            "      'encoded_image_string_tensor', 'tf_example'].\n",
            "    pipeline_config: pipeline_pb2.TrainAndEvalPipelineConfig proto.\n",
            "    trained_checkpoint_prefix: Path to the trained checkpoint file.\n",
            "    output_directory: Path to write outputs.\n",
            "    input_shape: Sets a fixed shape for an `image_tensor` input. If not\n",
            "      specified, will default to [None, None, None, 3].\n",
            "    output_collection_name: Name of collection to add output tensors to.\n",
            "      If None, does not add output tensors to a collection.\n",
            "    additional_output_tensor_names: list of additional output\n",
            "      tensors to include in the frozen graph.\n",
            "    write_inference_graph: If true, writes inference graph to disk.\n",
            "  \"\"\"\n",
            "  detection_model = model_builder.build(pipeline_config.model,\n",
            "                                        is_training=False)\n",
            "  graph_rewriter_fn = None\n",
            "  if pipeline_config.HasField('graph_rewriter'):\n",
            "    graph_rewriter_config = pipeline_config.graph_rewriter\n",
            "    graph_rewriter_fn = graph_rewriter_builder.build(graph_rewriter_config,\n",
            "                                                     is_training=False)\n",
            "  _export_inference_graph(\n",
            "      input_type,\n",
            "      detection_model,\n",
            "      pipeline_config.eval_config.use_moving_averages,\n",
            "      trained_checkpoint_prefix,\n",
            "      output_directory,\n",
            "      additional_output_tensor_names,\n",
            "      input_shape,\n",
            "      output_collection_name,\n",
            "      graph_hook_fn=graph_rewriter_fn,\n",
            "      write_inference_graph=write_inference_graph)\n",
            "  pipeline_config.eval_config.use_moving_averages = False\n",
            "  config_util.save_pipeline_config(pipeline_config, output_directory)\n",
            "\n",
            "\n",
            "def profile_inference_graph(graph):\n",
            "  \"\"\"Profiles the inference graph.\n",
            "\n",
            "  Prints model parameters and computation FLOPs given an inference graph.\n",
            "  BatchNorms are excluded from the parameter count due to the fact that\n",
            "  BatchNorms are usually folded. BatchNorm, Initializer, Regularizer\n",
            "  and BiasAdd are not considered in FLOP count.\n",
            "\n",
            "  Args:\n",
            "    graph: the inference graph.\n",
            "  \"\"\"\n",
            "  tfprof_vars_option = (\n",
            "      tf.contrib.tfprof.model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS)\n",
            "  tfprof_flops_option = tf.contrib.tfprof.model_analyzer.FLOAT_OPS_OPTIONS\n",
            "\n",
            "  # Batchnorm is usually folded during inference.\n",
            "  tfprof_vars_option['trim_name_regexes'] = ['.*BatchNorm.*']\n",
            "  # Initializer and Regularizer are only used in training.\n",
            "  tfprof_flops_option['trim_name_regexes'] = [\n",
            "      '.*BatchNorm.*', '.*Initializer.*', '.*Regularizer.*', '.*BiasAdd.*'\n",
            "  ]\n",
            "\n",
            "  tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
            "      graph,\n",
            "      tfprof_options=tfprof_vars_option)\n",
            "\n",
            "  tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
            "      graph,\n",
            "      tfprof_options=tfprof_flops_option)"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4_ZUt551OKg",
        "colab_type": "text"
      },
      "source": [
        "# updating export inference graph\n",
        "\n",
        "from: from object_detection import exporter\n",
        "\n",
        "to: from object_detection import updated_exporter as exporter \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1-n-5TS1UXP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b18b527b-9305-4b9d-bbda-bfdfa2c440e3"
      },
      "source": [
        "%cd /content/drive/'My Drive'/$maindirectory/models/research/object_detection\n",
        "!cat export_inference_graph.py"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research/object_detection\n",
            "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
            "#\n",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "# you may not use this file except in compliance with the License.\n",
            "# You may obtain a copy of the License at\n",
            "#\n",
            "#     http://www.apache.org/licenses/LICENSE-2.0\n",
            "#\n",
            "# Unless required by applicable law or agreed to in writing, software\n",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "# See the License for the specific language governing permissions and\n",
            "# limitations under the License.\n",
            "# ==============================================================================\n",
            "\n",
            "r\"\"\"Tool to export an object detection model for inference.\n",
            "\n",
            "Prepares an object detection tensorflow graph for inference using model\n",
            "configuration and a trained checkpoint. Outputs inference\n",
            "graph, associated checkpoint files, a frozen inference graph and a\n",
            "SavedModel (https://tensorflow.github.io/serving/serving_basic.html).\n",
            "\n",
            "The inference graph contains one of three input nodes depending on the user\n",
            "specified option.\n",
            "  * `image_tensor`: Accepts a uint8 4-D tensor of shape [None, None, None, 3]\n",
            "  * `encoded_image_string_tensor`: Accepts a 1-D string tensor of shape [None]\n",
            "    containing encoded PNG or JPEG images. Image resolutions are expected to be\n",
            "    the same if more than 1 image is provided.\n",
            "  * `tf_example`: Accepts a 1-D string tensor of shape [None] containing\n",
            "    serialized TFExample protos. Image resolutions are expected to be the same\n",
            "    if more than 1 image is provided.\n",
            "\n",
            "and the following output nodes returned by the model.postprocess(..):\n",
            "  * `num_detections`: Outputs float32 tensors of the form [batch]\n",
            "      that specifies the number of valid boxes per image in the batch.\n",
            "  * `detection_boxes`: Outputs float32 tensors of the form\n",
            "      [batch, num_boxes, 4] containing detected boxes.\n",
            "  * `detection_scores`: Outputs float32 tensors of the form\n",
            "      [batch, num_boxes] containing class scores for the detections.\n",
            "  * `detection_classes`: Outputs float32 tensors of the form\n",
            "      [batch, num_boxes] containing classes for the detections.\n",
            "  * `raw_detection_boxes`: Outputs float32 tensors of the form\n",
            "      [batch, raw_num_boxes, 4] containing detection boxes without\n",
            "      post-processing.\n",
            "  * `raw_detection_scores`: Outputs float32 tensors of the form\n",
            "      [batch, raw_num_boxes, num_classes_with_background] containing class score\n",
            "      logits for raw detection boxes.\n",
            "  * `detection_masks`: (Optional) Outputs float32 tensors of the form\n",
            "      [batch, num_boxes, mask_height, mask_width] containing predicted instance\n",
            "      masks for each box if its present in the dictionary of postprocessed\n",
            "      tensors returned by the model.\n",
            "  * detection_multiclass_scores: (Optional) Outputs float32 tensor of shape\n",
            "      [batch, num_boxes, num_classes_with_background] for containing class\n",
            "      score distribution for detected boxes including background if any.\n",
            "  * detection_features: (Optional) float32 tensor of shape\n",
            "      [batch, num_boxes, roi_height, roi_width, depth]\n",
            "  containing classifier features\n",
            "\n",
            "Notes:\n",
            " * This tool uses `use_moving_averages` from eval_config to decide which\n",
            "   weights to freeze.\n",
            "\n",
            "Example Usage:\n",
            "--------------\n",
            "python export_inference_graph \\\n",
            "    --input_type image_tensor \\\n",
            "    --pipeline_config_path path/to/ssd_inception_v2.config \\\n",
            "    --trained_checkpoint_prefix path/to/model.ckpt \\\n",
            "    --output_directory path/to/exported_model_directory\n",
            "\n",
            "The expected output would be in the directory\n",
            "path/to/exported_model_directory (which is created if it does not exist)\n",
            "with contents:\n",
            " - inference_graph.pbtxt\n",
            " - model.ckpt.data-00000-of-00001\n",
            " - model.ckpt.info\n",
            " - model.ckpt.meta\n",
            " - frozen_inference_graph.pb\n",
            " + saved_model (a directory)\n",
            "\n",
            "Config overrides (see the `config_override` flag) are text protobufs\n",
            "(also of type pipeline_pb2.TrainEvalPipelineConfig) which are used to override\n",
            "certain fields in the provided pipeline_config_path.  These are useful for\n",
            "making small changes to the inference graph that differ from the training or\n",
            "eval config.\n",
            "\n",
            "Example Usage (in which we change the second stage post-processing score\n",
            "threshold to be 0.5):\n",
            "\n",
            "python export_inference_graph \\\n",
            "    --input_type image_tensor \\\n",
            "    --pipeline_config_path path/to/ssd_inception_v2.config \\\n",
            "    --trained_checkpoint_prefix path/to/model.ckpt \\\n",
            "    --output_directory path/to/exported_model_directory \\\n",
            "    --config_override \" \\\n",
            "            model{ \\\n",
            "              faster_rcnn { \\\n",
            "                second_stage_post_processing { \\\n",
            "                  batch_non_max_suppression { \\\n",
            "                    score_threshold: 0.5 \\\n",
            "                  } \\\n",
            "                } \\\n",
            "              } \\\n",
            "            }\"\n",
            "\"\"\"\n",
            "import tensorflow as tf\n",
            "from google.protobuf import text_format\n",
            "from object_detection import updated_exporter as exporter\n",
            "from object_detection.protos import pipeline_pb2\n",
            "\n",
            "slim = tf.contrib.slim\n",
            "flags = tf.app.flags\n",
            "\n",
            "flags.DEFINE_string('input_type', 'image_tensor', 'Type of input node. Can be '\n",
            "                    'one of [`image_tensor`, `encoded_image_string_tensor`, '\n",
            "                    '`tf_example`]')\n",
            "flags.DEFINE_string('input_shape', None,\n",
            "                    'If input_type is `image_tensor`, this can explicitly set '\n",
            "                    'the shape of this input tensor to a fixed size. The '\n",
            "                    'dimensions are to be provided as a comma-separated list '\n",
            "                    'of integers. A value of -1 can be used for unknown '\n",
            "                    'dimensions. If not specified, for an `image_tensor, the '\n",
            "                    'default shape will be partially specified as '\n",
            "                    '`[None, None, None, 3]`.')\n",
            "flags.DEFINE_string('pipeline_config_path', None,\n",
            "                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
            "                    'file.')\n",
            "flags.DEFINE_string('trained_checkpoint_prefix', None,\n",
            "                    'Path to trained checkpoint, typically of the form '\n",
            "                    'path/to/model.ckpt')\n",
            "flags.DEFINE_string('output_directory', None, 'Path to write outputs.')\n",
            "flags.DEFINE_string('config_override', '',\n",
            "                    'pipeline_pb2.TrainEvalPipelineConfig '\n",
            "                    'text proto to override pipeline_config_path.')\n",
            "flags.DEFINE_boolean('write_inference_graph', False,\n",
            "                     'If true, writes inference graph to disk.')\n",
            "tf.app.flags.mark_flag_as_required('pipeline_config_path')\n",
            "tf.app.flags.mark_flag_as_required('trained_checkpoint_prefix')\n",
            "tf.app.flags.mark_flag_as_required('output_directory')\n",
            "FLAGS = flags.FLAGS\n",
            "\n",
            "\n",
            "def main(_):\n",
            "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
            "  with tf.gfile.GFile(FLAGS.pipeline_config_path, 'r') as f:\n",
            "    text_format.Merge(f.read(), pipeline_config)\n",
            "  text_format.Merge(FLAGS.config_override, pipeline_config)\n",
            "  if FLAGS.input_shape:\n",
            "    input_shape = [\n",
            "        int(dim) if dim != '-1' else None\n",
            "        for dim in FLAGS.input_shape.split(',')\n",
            "    ]\n",
            "  else:\n",
            "    input_shape = None\n",
            "  exporter.export_inference_graph(\n",
            "      FLAGS.input_type, pipeline_config, FLAGS.trained_checkpoint_prefix,\n",
            "      FLAGS.output_directory, input_shape=input_shape,\n",
            "      write_inference_graph=FLAGS.write_inference_graph)\n",
            "\n",
            "\n",
            "if __name__ == '__main__':\n",
            "  tf.app.run()"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpvmGgdoyJ6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b928454-fdc1-42d4-e438-db96af6855af"
      },
      "source": [
        "%%writefile export_inference_graph.py\n",
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "r\"\"\"Tool to export an object detection model for inference.\n",
        "\n",
        "Prepares an object detection tensorflow graph for inference using model\n",
        "configuration and a trained checkpoint. Outputs inference\n",
        "graph, associated checkpoint files, a frozen inference graph and a\n",
        "SavedModel (https://tensorflow.github.io/serving/serving_basic.html).\n",
        "\n",
        "The inference graph contains one of three input nodes depending on the user\n",
        "specified option.\n",
        "  * `image_tensor`: Accepts a uint8 4-D tensor of shape [None, None, None, 3]\n",
        "  * `encoded_image_string_tensor`: Accepts a 1-D string tensor of shape [None]\n",
        "    containing encoded PNG or JPEG images. Image resolutions are expected to be\n",
        "    the same if more than 1 image is provided.\n",
        "  * `tf_example`: Accepts a 1-D string tensor of shape [None] containing\n",
        "    serialized TFExample protos. Image resolutions are expected to be the same\n",
        "    if more than 1 image is provided.\n",
        "\n",
        "and the following output nodes returned by the model.postprocess(..):\n",
        "  * `num_detections`: Outputs float32 tensors of the form [batch]\n",
        "      that specifies the number of valid boxes per image in the batch.\n",
        "  * `detection_boxes`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes, 4] containing detected boxes.\n",
        "  * `detection_scores`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes] containing class scores for the detections.\n",
        "  * `detection_classes`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes] containing classes for the detections.\n",
        "  * `raw_detection_boxes`: Outputs float32 tensors of the form\n",
        "      [batch, raw_num_boxes, 4] containing detection boxes without\n",
        "      post-processing.\n",
        "  * `raw_detection_scores`: Outputs float32 tensors of the form\n",
        "      [batch, raw_num_boxes, num_classes_with_background] containing class score\n",
        "      logits for raw detection boxes.\n",
        "  * `detection_masks`: (Optional) Outputs float32 tensors of the form\n",
        "      [batch, num_boxes, mask_height, mask_width] containing predicted instance\n",
        "      masks for each box if its present in the dictionary of postprocessed\n",
        "      tensors returned by the model.\n",
        "  * detection_multiclass_scores: (Optional) Outputs float32 tensor of shape\n",
        "      [batch, num_boxes, num_classes_with_background] for containing class\n",
        "      score distribution for detected boxes including background if any.\n",
        "  * detection_features: (Optional) float32 tensor of shape\n",
        "      [batch, num_boxes, roi_height, roi_width, depth]\n",
        "  containing classifier features\n",
        "\n",
        "Notes:\n",
        " * This tool uses `use_moving_averages` from eval_config to decide which\n",
        "   weights to freeze.\n",
        "\n",
        "Example Usage:\n",
        "--------------\n",
        "python export_inference_graph \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path path/to/ssd_inception_v2.config \\\n",
        "    --trained_checkpoint_prefix path/to/model.ckpt \\\n",
        "    --output_directory path/to/exported_model_directory\n",
        "\n",
        "The expected output would be in the directory\n",
        "path/to/exported_model_directory (which is created if it does not exist)\n",
        "with contents:\n",
        " - inference_graph.pbtxt\n",
        " - model.ckpt.data-00000-of-00001\n",
        " - model.ckpt.info\n",
        " - model.ckpt.meta\n",
        " - frozen_inference_graph.pb\n",
        " + saved_model (a directory)\n",
        "\n",
        "Config overrides (see the `config_override` flag) are text protobufs\n",
        "(also of type pipeline_pb2.TrainEvalPipelineConfig) which are used to override\n",
        "certain fields in the provided pipeline_config_path.  These are useful for\n",
        "making small changes to the inference graph that differ from the training or\n",
        "eval config.\n",
        "\n",
        "Example Usage (in which we change the second stage post-processing score\n",
        "threshold to be 0.5):\n",
        "\n",
        "python export_inference_graph \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path path/to/ssd_inception_v2.config \\\n",
        "    --trained_checkpoint_prefix path/to/model.ckpt \\\n",
        "    --output_directory path/to/exported_model_directory \\\n",
        "    --config_override \" \\\n",
        "            model{ \\\n",
        "              faster_rcnn { \\\n",
        "                second_stage_post_processing { \\\n",
        "                  batch_non_max_suppression { \\\n",
        "                    score_threshold: 0.5 \\\n",
        "                  } \\\n",
        "                } \\\n",
        "              } \\\n",
        "            }\"\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection import updated_exporter as exporter\n",
        "from object_detection.protos import pipeline_pb2\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "flags = tf.app.flags\n",
        "\n",
        "flags.DEFINE_string('input_type', 'image_tensor', 'Type of input node. Can be '\n",
        "                    'one of [`image_tensor`, `encoded_image_string_tensor`, '\n",
        "                    '`tf_example`]')\n",
        "flags.DEFINE_string('input_shape', None,\n",
        "                    'If input_type is `image_tensor`, this can explicitly set '\n",
        "                    'the shape of this input tensor to a fixed size. The '\n",
        "                    'dimensions are to be provided as a comma-separated list '\n",
        "                    'of integers. A value of -1 can be used for unknown '\n",
        "                    'dimensions. If not specified, for an `image_tensor, the '\n",
        "                    'default shape will be partially specified as '\n",
        "                    '`[None, None, None, 3]`.')\n",
        "flags.DEFINE_string('pipeline_config_path', None,\n",
        "                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
        "                    'file.')\n",
        "flags.DEFINE_string('trained_checkpoint_prefix', None,\n",
        "                    'Path to trained checkpoint, typically of the form '\n",
        "                    'path/to/model.ckpt')\n",
        "flags.DEFINE_string('output_directory', None, 'Path to write outputs.')\n",
        "flags.DEFINE_string('config_override', '',\n",
        "                    'pipeline_pb2.TrainEvalPipelineConfig '\n",
        "                    'text proto to override pipeline_config_path.')\n",
        "flags.DEFINE_boolean('write_inference_graph', False,\n",
        "                     'If true, writes inference graph to disk.')\n",
        "tf.app.flags.mark_flag_as_required('pipeline_config_path')\n",
        "tf.app.flags.mark_flag_as_required('trained_checkpoint_prefix')\n",
        "tf.app.flags.mark_flag_as_required('output_directory')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def main(_):\n",
        "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "  with tf.gfile.GFile(FLAGS.pipeline_config_path, 'r') as f:\n",
        "    text_format.Merge(f.read(), pipeline_config)\n",
        "  text_format.Merge(FLAGS.config_override, pipeline_config)\n",
        "  if FLAGS.input_shape:\n",
        "    input_shape = [\n",
        "        int(dim) if dim != '-1' else None\n",
        "        for dim in FLAGS.input_shape.split(',')\n",
        "    ]\n",
        "  else:\n",
        "    input_shape = None\n",
        "  exporter.export_inference_graph(\n",
        "      FLAGS.input_type, pipeline_config, FLAGS.trained_checkpoint_prefix,\n",
        "      FLAGS.output_directory, input_shape=input_shape,\n",
        "      write_inference_graph=FLAGS.write_inference_graph)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting export_inference_graph.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gsa7q8SPF20",
        "colab_type": "text"
      },
      "source": [
        "# exporting model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4onn0dnOCJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5e179002-664a-4345-a01f-34df0b9ca69a"
      },
      "source": [
        "# so that latest model can be acquired from the training folder \n",
        "%cd /content/drive/'My Drive'/$maindirectory/models/research/\n",
        "directory_to_save_model = \"production_fine_tuned_model\"\n",
        "\n",
        "#dir where the model will be saved\n",
        "output_directory = './content/drive/My\\ Drive/{0}/models/research/{1}'.format(maindirectory, directory_to_save_model)\n",
        "\n",
        "lst = os.listdir('training')\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join('./content/drive/My\\ Drive/{0}/models/research'.format(maindirectory),'training', last_model)\n",
        "print(last_model_path)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/my_detector2/models/research\n",
            "./content/drive/My\\ Drive/my_detector2/models/research/training/model.ckpt-5409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvpFI-Sy2Gzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbbee236-fad1-4739-f82d-6174ac56032a"
      },
      "source": [
        "# exporting our model \n",
        "%cd ~/..\n",
        "!pwd\n",
        "\n",
        "# Configuration for model to be exported\n",
        "config_pathname = './content/drive/My\\ Drive/{}/models/research/object_detection/samples/configs/{}' \\\n",
        "                  .format(maindirectory, configfilename)\n",
        "\n",
        "# Model Version\n",
        "model_version_id = 1\n",
        "\n",
        "# Output Directory\n",
        "output_directory = output_directory + str(model_version_id)\n",
        "\n",
        "!python ./content/drive/'My Drive'/$maindirectory/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={config_pathname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "/\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From ./content/drive/My Drive/my_detector2/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From ./content/drive/My Drive/my_detector2/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0124 14:40:00.160491 140205970941824 module_wrapper.py:139] From ./content/drive/My Drive/my_detector2/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:394: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0124 14:40:00.170497 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:394: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:123: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0124 14:40:00.173710 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:123: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0124 14:40:00.224192 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0124 14:40:00.279082 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0124 14:40:00.289739 140205970941824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0124 14:40:02.123322 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 14:40:02.131482 140205970941824 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0124 14:40:02.131959 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 14:40:02.149967 140205970941824 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0124 14:40:02.150485 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0124 14:40:02.150659 140205970941824 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0124 14:40:02.220219 140205970941824 deprecation.py:323] From /content/drive/My Drive/my_detector2/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0124 14:40:03.010025 140205970941824 deprecation.py:506] From /content/drive/My Drive/my_detector2/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0124 14:40:03.032413 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0124 14:40:03.686261 140205970941824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 14:40:03.693526 140205970941824 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0124 14:40:03.721346 140205970941824 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0124 14:40:04.630847 140205970941824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:280: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0124 14:40:05.048787 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:280: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:375: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0124 14:40:05.049276 140205970941824 deprecation.py:323] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:375: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:407: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0124 14:40:05.053496 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:407: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:531: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0124 14:40:05.053794 140205970941824 deprecation.py:323] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:531: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0124 14:40:05.054950 140205970941824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "242 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/12.87m params)\n",
            "  Conv (--/2.65m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/4.25m params)\n",
            "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "  SecondStageBoxPredictor (--/31.77k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/24.60k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x24, 24.58k/24.58k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/7.17k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (7, 7/7 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (1024x7, 7.17k/7.17k params)\n",
            "  SecondStageFeatureExtractor (--/5.89m params)\n",
            "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "242 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/6.18k flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:424: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0124 14:40:06.686473 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:424: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:334: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0124 14:40:07.806707 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:334: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-01-24 14:40:07.808080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-01-24 14:40:07.809806: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-01-24 14:40:07.809851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (9ac5f5efd728): /proc/driver/nvidia/version does not exist\n",
            "2020-01-24 14:40:07.810198: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-01-24 14:40:07.815293: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
            "2020-01-24 14:40:07.815515: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13c1800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-24 14:40:07.815549: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "INFO:tensorflow:Restoring parameters from ./content/drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "I0124 14:40:07.819244 140205970941824 saver.py:1284] Restoring parameters from ./content/drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0124 14:40:09.423154 140205970941824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./content/drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "I0124 14:40:10.286661 140205970941824 saver.py:1284] Restoring parameters from ./content/drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0124 14:40:11.233987 140205970941824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0124 14:40:11.234303 140205970941824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 356 variables.\n",
            "I0124 14:40:11.735361 140205970941824 graph_util_impl.py:334] Froze 356 variables.\n",
            "INFO:tensorflow:Converted 356 variables to const ops.\n",
            "I0124 14:40:11.881656 140205970941824 graph_util_impl.py:394] Converted 356 variables to const ops.\n",
            "INFO:tensorflow:Restoring parameters from ./content/drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "I0124 14:40:12.523334 140205970941824 saver.py:1284] Restoring parameters from ./content/drive/My Drive/my_detector2/models/research/training/model.ckpt-5409\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:299: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0124 14:40:13.522634 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:299: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:302: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0124 14:40:13.525830 140205970941824 deprecation.py:323] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:302: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:308: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0124 14:40:13.526683 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:308: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:314: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0124 14:40:13.527107 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/updated_exporter.py:314: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0124 14:40:13.527573 140205970941824 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0124 14:40:13.527718 140205970941824 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./content/drive/My Drive/my_detector2/models/research/production_fine_tuned_model1111/saved_model/saved_model.pb\n",
            "I0124 14:40:16.053754 140205970941824 builder_impl.py:425] SavedModel written to: ./content/drive/My Drive/my_detector2/models/research/production_fine_tuned_model1111/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/drive/My Drive/my_detector2/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0124 14:40:16.185476 140205970941824 module_wrapper.py:139] From /content/drive/My Drive/my_detector2/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to ./content/drive/My Drive/my_detector2/models/research/production_fine_tuned_model1111/pipeline.config\n",
            "I0124 14:40:16.185918 140205970941824 config_util.py:190] Writing pipeline config file to ./content/drive/My Drive/my_detector2/models/research/production_fine_tuned_model1111/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QppxhUtBC48b",
        "colab_type": "text"
      },
      "source": [
        "# download the saved model folder and variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9zduDQYNgW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ~/..\n",
        "from google.colab import files\n",
        "basepath = '/content/drive/My Drive/{0}/models/research/{1}{2}/'.format(maindirectory, directory_to_save_model, model_version_id)\n",
        "files.download(basepath + 'pipeline.config')\n",
        "files.download(basepath + 'saved_model/saved_model.pb')\n",
        "files.download(basepath + 'saved_model/variables/variables.index')\n",
        "files.download(basepath + 'saved_model/variables/variables.data-00000-of-00001')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}